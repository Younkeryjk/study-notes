#  MySQL

### MySQL架构

* MySQL包括Server层和存储引擎层两部分

* Server层

  Server层包括连接器、 查询缓存、 分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数(如日期、时间、数学和加密函数等)，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。

* 存储引擎层

  存储引擎层负责数据的存储和提取，其架构模式是插件式的；支持 InnoDB、MyISAM、Memory等多个存储引擎 ；

   **现在最常用的存储引擎是InnoDB， 从MySQL5.5.5开始 成为了默认存储引擎。** 

   不同的存储引擎共用一个**Server层**，也就是从连接器到执行器的部分。 

*  SQL语句执行流程 

   你要做什么=》分析器 

   要怎么做 =》 优化器

   做=》 执行器 

  1. 连接器：**管理链接，权限验证**

     负责跟客户端建立连接、获取权限、维持和管理连接

      mysql -h$ip -P$port -u$user -p 

     - **如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。**

       **这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。** 

     -  wait_timeout

       如果客户端太长时间没有动静，连接器就会自动将它端口。这个时间由参数wait_timeout设置，默认是8小时

     -  长连接

        长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。 

       建立连接的过程通常是比较复杂的，在使用中要尽量减少建立连接的动作，也就是**尽量使用长连接**。 

       **缺点是内存涨得特别快**，这是因为MySQL在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。  两种解决方案：

       1.   定期断开长连接。 

          使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。 

       2.  如果你用的是**MySQL 5.7或更新版本，**可以在每次执行一个比较大的操作后，通过执行 **mysql_reset_connection**来重新初始化连接资源。 

           **这个过程不需要重连和重新做权限验证**，但是会将连接恢复到刚刚创建完时的状态。 

  2. 查询缓存

     MySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。  如果查询命中缓存，MySQL不需要执行后面的复杂操作，就可以直接返回结果

     * **不要使用查询缓存， 因为查询缓存往往弊大于利。** 

        只要有对一个表的更新，这个表上所有的查询缓存都会被清空。  除非你的业务就是有一张静态表，很长时间才会更新一次。 

     *  按需使用 ，可以用SQL_CACHE显式指定  

        select SQL_CACHE * from T where ID=10； 

     *  **MySQL 8.0版本直接将查询缓存的整块功能删掉了** 

  3. 分析器：词法分析、语法分析

     *  词法分析

        MySQL需要识别出里面的字符串分别是什么，代表什么 

       MySQL从你输入的"select"这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名T”，把字符串“ID”识别成“列ID” 

     *  语法分析 

        判断你输入的这个SQL语句是否满足MySQL语法 

        一般语法错误会提示第一个出现错误的位置，  要关注的是**紧接“use near”的内容**。 

  4. 优化器：执行计划生成、索引选择

     **经过了分析器，MySQL就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。** 

     优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。 

     优化器阶段完成后，这个语句的执行方案就确定下来了 

  5. 执行器：操作引擎，返回结果

     MySQL通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。 

     开始执行的时候，要先判断一下你对这个表T有没有执行查询的权限； 如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。 

     例： select * from T where ID=10; 

     比如我们这个例子中的表T中，ID字段没有索引，那么执行器的执行流程是这样的： 

     1.  调用InnoDB引擎接口取这个表的第一行，判断ID值是不是10，如果不是则跳过，如果是则将这行存在结果集中； 
     2.  调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。 
     3.  执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。 

     *  rows_examined 

        慢查询日志有 一个rows_examined的字段，表示这个语句执行过程中扫描了多少行。 

       在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此**引擎扫描行数跟rows_examined并不是完全相同的。** 

### 日志系统

**redo log主要用于崩溃恢复，bin log主要用于备份**

#### redo log(重做日志)

redo log用于保证crash-safe能力。innodb_flush_log_at_trx_commit这个参数设置成1的时候，表示每次事务的redo log都直接持久化到磁盘。**这个参数建议设置成1，这样可以保证MySQL异常重启之后数据不丢失。** 

* WAL技术

  WAL的全称是Write-Ahead Logging，它的关键点就是先写日志后写磁盘。
  
  **如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高** 

当有一条记录需要更新的时候， InnoDB引擎就会先把记录写到redo log里，并更新内存，这个时候更新就算完成了。同时， InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里，而这个更新往往是在系统比较空闲的时候做。

InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB，那么总共可以记录4GB的操作。从头开始写，写到末尾就又回到开头循环写。

*  write pos

   write pos是当前记录的位置，一边写一边后移； 写到文件末尾后就回到文件开头重新写。 

*  checkpoint

   checkpoint是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。 

 write pos和checkpoint之间的是还空着的部分，可以用来记录新的操作。如果write pos追上checkpoint，表示 满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把checkpoint推进一下。 

*   **crash-safe**

   有了redo log，InnoDB就**可以保证即使数据库发生异常重启，之前提交的记录都不会丢失**，这个能力称为**crash-safe**。 

#### bin log( 归档日志 )

redo log是InnoDB引擎特有的日志，而Server层也有自己的日志，称为binlog（归档日志） 

sync_binlog这个参数设置成1的时候，表示每次事务的binlog都持久化到磁盘。**这个参数也建议设置成1，这样可以保证MySQL异常重启之后binlog不丢失。** 

 为什么会有两份日志呢？ 

因为最开始MySQL里并没有InnoDB引擎。MySQL自带的引擎是MyISAM，但是MyISAM没有crash-safe的能力，binlog日志只能用于归档。  InnoDB使用另外一套日志系统——也就是redo log来实现crash-safe能力 

这两种日志有以下三点不同：

1.  redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。 
2. redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1”
3. redo log是循环写的，空间固定会用完；binlog是可以追加写的

###### binlog的三种格式

例： delete from t  where a>=4 and t_modified<='2018-11-10' limit 1; 

1.  statement 

   binlog里面记录的就是**SQL语句的原文** 

   delete from t  where a>=4 and t_modified<='2018-11-10' limit 1; 

   语句中有limit，这个命令可能是unsafe的；因为delete 带limit，**很可能会出现主备数据不一致的情况**。  

   如果delete语句使用的是索引a，那么会根据索引a找到第一个满足条件的行，也就是说删除的是a=4这一行； 

   但如果使用的是索引t_modified，那么删除的就是 t_modified='2018-11-09’也就是a=5这一行。 

   **由于statement格式下，记录到binlog里的是语句原文，因此可能会出现这样一种情况：在主库执行这条SQL语句的时候，用的是索引a；而在备库执行这条SQL语句的时候，却使用了索引t_modified**。因此，MySQL认为这样写是有风险的。 

2.  row 

   binlog里面记录了**真实删除行的主键id**，这样binlog传到备库去的时候，就肯定会删除id=4的行，不会有主备删除不同行的问题。 

3.  mixed 

   其实它就是前两种格式的混合；

   为什么会有mixed格式的binlog？

   * 因为有些statement格式的binlog可能会导致主备不一致，所以要使用row格式。

   *  但row格式的缺点是，很占空间 

     比如你用一个delete语句删掉10万行数据，用statement的话就是一个SQL语句被记录到binlog中，占用几十个字节的空间。但如果用row格式的binlog，就要把这10万条记录都写到binlog中。 

   * 所以，MySQL就取了个折中方案，也就是有了mixed格式的binlog。**mixed格式的意思是，MySQL自己会判断这条SQL语句是否可能引起主备不一致，如果有可能，就用row格式，否则就用statement格式。**

     mixed格式可以利用statment格式的优点，同时又避免了数据不一致的风险。 

     因此线上MySQL设置的binlog格式是statement的话，那基本上就可以认为这是一个不合理的设置。 至少应该把binlog的格式设置为mixed。 

     比如这个例子，设置为mixed后，就会记录为row格式；而如果执行的语句去掉limit 1，就会记录为statement格式。 

   现在越来越多的场景要求把MySQL的binlog格式设置成row，理由有很多，其中一个是**恢复数据**。 

   如果你在执行完一条delete语句以后，发现删错数据了，可以直接把binlog中记录的delete语句转成insert，把被错删的数据插入回去就可以恢复了。  insert类似； update只需要把这个event前后的两行信息对调一下 

   binlog来恢复数据的标准做法是： 用 mysqlbinlog工具解析出来，然后把解析结果整个发给MySQL执行。类似下面的命令： 

   ```
   mysqlbinlog master.000001  --start-position=2738 --stop-position=2973 | mysql -h127.0.0.1 -P13000 -u$user -p$pwd;
   ```

#### 两阶段提交

 **为什么必须有“两阶段提交”呢？这是为了让两份日志之间的逻辑一致，保证数据的一致性** 

* 简单的update语句的内部流程
  1. 执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据页本来就在内存中，直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。
  2. 执行器拿到引擎给的行数据，把这个值加1，得到新的一行数据，再调用引擎接口写入这行新数据
  3. 引擎**将这行新数据更新到内存中，同时将这个更新操作记录到redo log里，此时redo log处于prepare状态。**然后告知执行器执行完了，随时可以提交事务。
  4. 执行器生成这个操作的binlog，并把**binlog写入磁盘**。
  5. 执行器调用引擎的提交事务接口，引擎**把刚刚写入的redo log改为提交状态(commint)**，更新完成。

 **redo log和binlog都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。** 

#### 脏页

* 脏页

  当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为脏页；内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一直了，称为干净页

* 更新和flush过程

   ![img](https://static001.geekbang.org/resource/image/34/da/349cfab9e4f5d2a75e07b2132a301fda.jpeg) 

  **平时执行很快的更新操作，其实就是在写内存和日志，而MySQL偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）。** 

*  什么情况会引发数据库的flush过程呢？ 

  *  redo log写满了

    这时候系统会停止所有更新操作，把checkpoint往前推进，redo log留出空间可以继续写， 对应的所有脏页都flush到磁盘上。 

    这种情况是InnoDB**要尽量避免**的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你**从监控上看，这时候更新数会跌为0**。 

  *  系统内存不足 

    当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘，**这种情况其实是常态**。 

  *  MySQL认为系统“空闲”的时候 

     见缝插针地找时间，只要有机会就刷一点“脏页” 

  *  MySQL正常关闭的时候 

    MySQL会把内存的脏页都flush到磁盘上，这样下次MySQL启动的时候，就可以直接从磁盘上读数据，启动速度会很快。 

*  刷脏页时会明显影响性能的情况

  1.  一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长； 

  2.  日志写满，更新全部堵住，写性能跌为0，这种情况对敏感业务来说，是不能接受的。 

      InnoDB需要有控制脏页比例的机制，来尽量避免上面的这两种情况

* 刷脏页的控制策略

  *  innodb_io_capacity 

    它会告诉InnoDB你的磁盘能力。这个值我建议你设置成磁盘的IOPS 

    如果刷脏页刷得特别慢，甚至比脏页生成的速度还慢，这样就造成了脏页累积，影响了查询和更新性能。 

  * innodb_max_dirty_pages_pct 

    脏页比例上限 ，默认值是75%。  

    **要合理地设置innodb_io_capacity的值，并且平时要多关注脏页比例，不要让它经常接近75%。** 

  *  计算脏页比例

    脏页比例是通过Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total得到的 

    ```
    mysql> select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_dirty';
    select VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_total';
    select @a/@b;
    ```

  *  innodb_flush_neighbors

    MySQL中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。 

    **值为1的时候会有上述的“连坐”机制，值为0时表示不找邻居，自己刷自己的。** 

    找“邻居”这个优化在机械硬盘时代是很有意义的，可以减少很多随机IO。  而如果使用的是SSD这类IOPS比较高的设备的话，就建议把innodb_flush_neighbors的值设置成0。

    在MySQL 8.0中，innodb_flush_neighbors参数的默认值已经是0了。 

### 事务

####  事务的四个特性

 **ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）** 

* 原子性:

  一个事务必须被视为一个不可分割的最小工作单元，整个事务中的所有操作要么全部提交成功，要么
  全部失败回滚，对于一个事务来说，不可能只执行其中的一部分操作，这就是事务的原子性

* 一致性:

  数据库总是从一个一致性的状态转换到另一个一致性的状态

* 隔离性:
  通常来说，一个事务所做的修改操作在提交事务之前，对于其他事务来说是不可见的

* 持久性:
  一旦事务提交，则其所做的修改会永久保存到数据库。

#### 事务的隔离性

*  为什么会有隔离级别？

  当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题，为了解决这些问题，就有了“隔离级别”的概念。 

*  脏读

  当数据库中一个事务A正在修改一个数据但是还未提交或者回滚，另一个事务B 来读取了修改后的内容并且使用了，之后事务A提交了，此时就引起了脏读。   **此情况仅会发生在： 读未提交的的隔离级别** 

* 不可重复读

  在一个事务A中多次操作数据，在事务操作过程中(未最终提交)，事务B也才做了处理，并且该值发生了改变，这时候就会导致A在事务操作的时候，发现数据与第一次不一样了。 就是不可重复读。 

  **此情况仅会发生在：读未提交、读提交的隔离级别**

* 幻读

  一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为幻读。 

  幻读是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，比如这种修改涉及到表中的“全部数据行”。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入“一行新数据”。那么，以后就会发生操作第一个事务的用户发现表中还存在没有修改的数据行，就好象发生了幻觉一样.
  一般解决幻读的方法是增加范围锁RangeS，锁定检索范围为只读，这样就避免了幻读。

  **此情况会回发生在：读未提交、读提交、可重复读的隔离级别**

**隔离得越严实，效率就会越低； 四种隔离级别性能依次降低，安全性依次提高**  

######  隔离级别

1.  读未提交（read uncommitted） 

   一个事务还没提交时，它做的变更就能被别的事务看到

2.  读提交（read committed） 

   一个事务提交后，它做的变更才会被别的事务看到

3.  可重复读（repeatable read） 

   一个事务执行过程中看到的数据，总是跟这个事务启动时看到的数据是一致的。

4.  串行化（serializable ） 

   对于同一行记录，写会加写锁，读会加读锁；当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。
   
   读-读：允许并发执行 ；读-写：只能串行；写-写：只能串行 

例：

```
mysql> create table T(c int) engine=InnoDB;
insert into T(c) values(1);
```

![img](https://static001.geekbang.org/resource/image/7d/f8/7dea45932a6b722eb069d2264d0066f8.png) 

 不同的隔离级别下，事务A会有哪些不同的返回结果：

- 若隔离级别是“读未提交”， 则V1的值就是2。这时候事务B虽然还没有提交，但是结果已经被A看到了。因此，V2、V3也都是2。
- 若隔离级别是“读提交”，则V1是1，V2的值是2。事务B的更新在提交后才能被A看到。所以， V3的值也是2。
- 若隔离级别是“可重复读”，则V1、V2是1，V3是2。之所以V2还是1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。
- 若隔离级别是“串行化”，则在事务B执行“将1改成2”的时候，会被锁住。直到事务A提交后，事务B才可以继续执行。所以从A的角度看， V1、V2值是1，V3的值是2。

 **在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。** 

**视图理解为数据副本，每次创建视图时，将当前『已持久化的数据』创建副本，后续直接从副本读取，从而达到数据隔离效果。**

* 在“可重复读”隔离级别下，这个视图是在**事务启动时创建**的，整个事务存在期间都用这个视图。
* 在“读提交”隔离级别下，这个视图是在**每个SQL语句开始执行的时候**创建的。
* “读未提交”隔离级别下直接返回记录上的最新值，没有视图概念。
* 而“串行化”隔离级别下直接用加锁的方式来避免并行访问。 

 配置方式： 启动参数**transaction-isolation**

######  事务隔离的实现

**每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。** 

例： 假设一个值从1被按顺序改成了2、3、4，在回滚日志里面就会有类似下面的记录。 

 ![img](https://static001.geekbang.org/resource/image/d9/ee/d9c313809e5ac148fc39feff532f0fee.png) 

###### 多版本并发控制（MVCC）

同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC） 

######  长事务

**尽量不要使用长事务**， 长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量**占用存储空间** 。除此之外，长事务还**占用锁资源**，可能会拖垮库。 

######  查询长事务

可以在information_schema库的innodb_trx这个表中查询长事务，比如下面这个语句，用于查找持续时间超过60s的事务。 

```
select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60
```

######  如何避免长事务对业务的影响？ 

我们可以从应用开发端和数据库端来看。

**首先，从应用开发端来看：**

1. 确认是否使用了set autocommit=0。这个确认工作可以在测试环境中开展，把MySQL的general_log开起来，然后随便跑一个业务逻辑，通过general_log的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成1。
2. 确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用begin/commit框起来。我见过有些是业务并没有这个需要，但是也把好几个select语句放到了事务中。这种只读事务可以去掉。
3. 业务连接数据库的时候，根据业务本身的预估，通过SET MAX_EXECUTION_TIME命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。（为什么会意外？在后续的文章中会提到这类案例）

**其次，从数据库端来看：**

1. 监控 information_schema.Innodb_trx表，设置长事务阈值，超过就报警/或者kill；
2. Percona的pt-kill这个工具不错，推荐使用；
3. 在业务功能测试阶段要求输出所有的general_log，分析日志行为提前发现问题；
4. 如果使用的是MySQL 5.6或者更新版本，把innodb_undo_tablespaces设置成2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。

####  事务的启动方式

启动方式有以下两种：

1.  显式启动事务语句

    begin 或 start transaction。配套的提交语句是commit，回滚语句是rollback。 

2.  set autocommit=0 

    这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个select语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行commit 或 rollback 语句，或者断开连接。 

 **建议总是使用set autocommit=1, 通过显式语句的方式来启动事务。** 

######  commit work and chain

对于一个需要频繁使用事务的业务，第二种方式每个事务在开始时都不需要主动执行一次 “begin”，减少了语句的交互次数；建议你使用commit work and chain语法。 

在autocommit为1的情况下，用begin显式启动的事务，如果执行commit则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行begin语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。 

### 索引

为什么会有索引？

索引的出现其实就是**为了提高数据查询的效率**，就像书的目录一样。 

#### 索引的常见模型

######  哈希表

哈希表是一种以键-值（key-value）存储数据的结构，我们只要输入待查找的值即key，就可以找到其对应的值即Value。 

哈希的思路很简单，把值放在数组里，用一个哈希函数把key换算成一个确定的位置，然后把value放在数组的这个位置。 

* 哈希冲突

   多个key值经过哈希函数的换算，会出现同一个值的情况。**处理这种情况的一种方法是，拉出一个链表**。 

* 优缺点：

  哈希的值并不是递增的，这样做的好处是增加新的值时速度会很快，只需要往后追加。 但缺点是，因为不是有序的，所以哈希索引做区间查询的速度是很慢的。 

 **哈希表这种结构适用于只有等值查询的场景**，比如Memcached及其他一些NoSQL引擎。 

######  有序数组

按顺序存储。查询用二分法就可以快速查询， 时间复杂度是O(log(N)) 

**有序数组在等值查询和范围查询场景中的性能就都非常优秀**。 

如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。 简单说来**查询效率高，更新效率低 。**

**有序数组索引只适用于静态存储引擎**，比如你要保存的是2017年某个城市的所有人口信息，这类不会再修改的数据。 

######  二叉搜索树 

*  二叉搜索树的特点：

   **每个节点的左儿子小于父节点，父节点又小于右儿子。** 

 **查找时间复杂度是O(log(N))** ， 为了维持O(log(N))的查询复杂度，你就需要保持这棵树是平衡二叉树。 为了做这个保证，**更新的时间复杂度也是O(log(N))**。 

*  多叉树

   树可以有二叉，也可以有多叉。多叉树就是每个节点有多个儿子，儿子之间的大小保证从左到右递增。  二叉树是搜索效率最高的，但是实际上**大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。** 

  为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N叉”树。 

  **N叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。** 

#### InnoDB 的索引模型

###### 索引组织表

在InnoDB中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。 

**InnoDB使用了B+树索引模型**，所以数据都是存储在B+树中的。

**每一个索引在InnoDB里面对应一棵B+树。**

 ![img](https://static001.geekbang.org/resource/image/dc/8d/dcda101051f28502bd5c4402b292e38d.png) 

######  索引类型

根据叶子节点的内容，**索引类型分为主键索引和非主键索引。** 

######  主键索引

主键索引的叶子节点存的是整行数据。在InnoDB里，主键索引也被称为聚簇索引（clustered index）。 

######  非主键索引

非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为二级索引（secondary index）。 

######  回表

普通索引查询方式，需要先搜索普通索引树，得到ID的值； 再到ID索引树搜索一次。这个过程称为回表。 

###### **基于主键索引和普通索引的查询有什么区别？** 

**基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。** 

#### 索引维护

###### 页分裂 

如果所在的数据页已经满了，根据B+树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂；会导致性能下降，空间利用率降低大概50%  

###### 自增主键

自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： NOT NULL PRIMARY KEY AUTO_INCREMENT。 

自增主键的插入数据模式，每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。 而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。 

除了考虑性能外，我们还可以从存储空间的角度来看。 

由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约20个字节，而如果用整型做主键，则只要4个字节，如果是长整型（bigint）则是8个字节。 

**显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。** 

所以，**从性能和存储空间方面考量，自增主键往往是更合理的选择。** 

#### 覆盖索引

 查询结果所需要的数据只在主键索引上有，所以不得不回表 。那么，有没有可能经过索引优化，避免回表过程呢？ 

**在查询里面，索引如果已经“覆盖了”我们的查询需求，我们称为覆盖索引。**  

**由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。**

**索引字段的维护总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。**  

#### 最左前缀原则

 如果为每一种查询都设计一个索引，索引是不是太多了？

 **B+树这种索引结构，可以利用索引的“最左前缀”，来定位记录。** 

 ![img](https://static001.geekbang.org/resource/image/89/70/89f74c631110cfbc83298ef27dcd6370.jpg) 

 **索引项是按照索引定义里面出现的字段顺序排序的**。 

不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个**最左前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符。** 

在建立联合索引的时候，如何安排索引内的字段顺序？

我们的评估标准是，**索引的复用能力**。因为可以支持最左前缀，所以当已经有了(a,b)这个联合索引后，一般就不需要单独在a上建立索引了。因此，**第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。** 

如果既有联合查询，又有基于a、b各自的查询呢？查询条件里面只有b的语句，是无法使用(a,b)这个联合索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护(a,b)、(b) 这两个索引。这时候，我们要**考虑的原则就是空间**了。 比如上面这个市民表的情况，name字段是比age字段大的 ，那我就建议你创建一个（name,age)的联合索引和一个(age)的单字段索引。 

#### 索引下推

例： 以市民表的联合索引（name, age）为例。如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是10岁的所有男孩”。那么，SQL语句是这么写的： 

```
mysql> select * from tuser where name like '张%' and age=10 and ismale=1;
```

这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录 ID3 。然后呢？当然是判断其他条件是否满足。

在MySQL 5.6之前，只能从ID3开始一个个回表。到主键索引上找出数据行，再对比字段值。 

而MySQL 5.6 引入的索引下推优化（index condition pushdown)， **可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。** 

 ![img](https://static001.geekbang.org/resource/image/b3/ac/b32aa8b1f75611e0759e52f5915539ac.jpg) 

 ![img](https://static001.geekbang.org/resource/image/76/1b/76e385f3df5a694cc4238c7b65acfe1b.jpg) 

 每一个虚线箭头表示回表一次。 

图1中，在(name,age)索引里面我特意去掉了age的值，这个过程InnoDB并不会去看age的值，只是按顺序把“name第一个字是’张’”的记录一条条取出来回表。因此，需要回表4次。

图2跟图1的区别是，**InnoDB在(name,age)索引内部就判断了age是否等于10，对于不等于10的记录，直接判断并跳过。**在我们的这个例子中，**只需要对ID4、ID5这两条记录回表取数据判断**，就只需要回表2次。

**在满足语句需求的情况下， 尽量少地访问资源是数据库设计的重要原则之一。**我们在使用数据库的时候，尤其是在设计表结构时，也要以减少资源消耗作为目标。 

####  change buffer

* 普通索引与唯一索引的性能对比

  * 查询过程：

    *  普通索引

       查到满足条件的第一个记录后，继续查找下一个记录，直到第一个不满足条件的记录 

    *  唯一索引 

       由于索引唯一性，查到第一个满足条件的记录后，停止检索 

     两者的性能差距微乎其微。因为InnoDB根据数据页来读写的

  *  更新过程：

    *  **这个记录要更新的目标页在内存中**
      * 对于唯一索引来说，找到3和5之间的位置，判断到没有冲突，插入这个值，语句执行结束；
      * 对于普通索引来说，找到3和5之间的位置，插入这个值，语句执行结束。
    *  **这个记录要更新的目标页不在内存中** 
      - 对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束
      -  对于普通索引来说，则是将更新记录在change buffer，语句执行就结束了 
    * 所以普通索引可以使用 change buffer；而唯一索引所有的更新操作都要先判断这个操作是否违反唯一性约束。  而这**必须要将数据页读入内存才能判断**。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用change buffer了。 

* change buffer

  当需要更新一个数据页，如果数据页在内存中就直接更新，如果不在内存中，在不影响数据一致性的前提下，InnoDB会将这些更新操作缓存在change buffer中 ，这样就不需要从磁盘中读入这个数据页了 。下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中的与这个页有关的操作。 

  change buffer是可以持久化的数据。在内存中有拷贝，也会被写入到磁盘上

  如果能够将更新操作先记录在change buffer，减少读磁盘，**语句的执行速度会得到明显的提升**。而且，数据读入内存是需要占用buffer pool的，所以这种方式**还能够避免占用内存，提高内存利用率**。 

  将数据从磁盘读入内存涉及随机IO的访问，是数据库里面成本最高的操作之一。 change buffer 因为减少了随机磁盘访问，所以对更新性能的提升很明显。

  * merge

    将change buffer中的操作应用到原数据页上，得到最新结果的过程，称为merge

     访问这个数据页会触发merge，系统有后台线程定期merge，在数据库正常关闭的过程中，也会执行  merge

  * innodb_change_buffer_max_size

    change buffer的大小，可以通过参数innodb_change_buffer_max_size来动态设置。这个参数设置为50的时候，表示change buffer的大小最多只能占用buffer pool的50%。

* change buffer的使用场景

   因为merge的时候是真正进行数据更新的时刻，而change buffer的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做merge之前，change buffer记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。 

   对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时change buffer的使用效果最好 。这种业务模型常见的就是账单类、日志类的系统。 

   如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭change buffer。而在其他情况下，change buffer都能提升更新性能。 

   **普通索引和change buffer的配合使用，对于数据量大的表的更新优化还是很明显的** 

   当你有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，那你应该特别关注这些表里的索引，尽量使用普通索引，然后把change buffer 尽量开大  

  **由于唯一索引用不上change buffer的优化机制，因此如果业务可以接受，从性能角度出发我建议你优先考虑非唯一索引。** 

* change buffer 和 redo log

  **redo log 主要节省的是随机写磁盘的IO消耗（转成顺序写），而change buffer主要节省的则是随机读磁盘的IO消耗。**

#### 优化器选错索引

*  对于由于索引统计信息不准确导致的问题

   可以用analyze table来解决

*  对于其他优化器误判的情况 

  * 可以在应用端用force index来强行指定索引
  * 也可以通过修改语句来引导优化器
  * 还可以通过增加或者删除索引来绕过这个问题。 

#### 字符串前缀索引

* 直接创建完整索引，比较占用空间

* 创建前缀索引也可以指定前缀长度，如果不指定，那么索引就会包含整个字符串

   add index index(email(6))

*  **使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本** 

*  区分度 

   算出字段不同长度的前缀的区分度，选择一个合适的前缀长度

  ```
  select 
    count(distinct left(email,4)）as L4,
    count(distinct left(email,5)）as L5,
    count(distinct left(email,6)）as L6,
    count(distinct left(email,7)）as L7,
  from User
  ```

*  创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引 

*  等值查询的处理方法

  既可以占用更小的空间，也能达到相同的查询效率的方法

  1.  **使用倒序存储** 

     ```
     select field_list from t where id_card = reverse('input_id_card_string');
     ```

  2.  **使用hash字段** 

      在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。 

     ```
     alter table t add id_card_crc int unsigned, add index(id_card_crc);
     ```

     ```
     select field_list from t where id_card_crc=crc32('input_id_card_string') and id_card='input_id_card_string'
     ```

     **使用倒序存储和使用hash字段这两种方法的异同点**：

     相同点是，都不支持范围查询 

     从查询效率上看，**使用hash字段方式的查询性能相对更稳定一些**。因为crc32算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近1。**而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数**。 

#### 用不上索引的情况

*  **对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。** 

* **索引字段不能进行函数操作，但是索引字段的参数可以进行函数操作**

* 条件字段函数操作

* 隐式类型转换

  **字符串和数字做比较的话，是将字符串转换成数字。** 

  * 所以字段类型是 char或varchar， 而输入的参数却是整型，所以需要做类型转换，放弃走索引

    例： select * from tradelog where tradeid=110717;  

    对于优化器来说，这个语句相当于： 

    select * from tradelog where  CAST(tradid AS signed int) = 110717; 

  * 字段类型是int，而输入的参数是字符串，输入的参数字符串默认会转成int，可以走索引；

    例： select * from tradelog where id="83126"; 

    对于优化器来说，这个语句相当于： 

    select * from tradelog where  id=CAST("83126" AS signed int) ; 

     索引字段不能进行函数操作，但是索引字段的参数可以进行函数操作

* 隐式字符编码转换

   字符集utf8mb4是utf8的超集，所以当这两个类型的字符串在做比较的时候，  MySQL内部的操作是，先把utf8字符串转成utf8mb4字符集，再做比较。 ( 类似地，在程序设计语言里面，做自动类型转换的时候，为了避免数据在转换过程中由于截断导致数据错误，也都是“按数据长度增加的方向”进行转换的 )

  例： select * from trade_detail  where CONVERT(traideid USING utf8mb4)=$L2.tradeid.value;  

   CONVERT()函数，在这里的意思是把输入的字符串转成utf8mb4字符集；即是对索引字段做函数操作，优化器会放弃走树搜索功能 

   而select operator from tradelog  where traideid =CONVERT($R4.tradeid.value USING utf8mb4);  

   这里的CONVERT函数是加在输入参数上的， 所以还可以走树搜索功能

*  优化器“偷懒”的情况

  即使简单地把where id+1=1000改写成where id=1000-1就能够用上索引快速查找，也不会主动做这个语句重写。 

### 锁

为什么会有锁？

锁设计的初衷是处理并发问题。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则；而锁就是用来实现这些访问规则的重要数据结构。

* 锁的分类：
  1. 全局锁
  2. 表级锁
  3. 行锁

#### 全局锁

全局锁就是对整个数据库实例加锁。 

加全局读锁的命令： **Flush tables with read lock (FTWRL)**  。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改（DML) ）、数据定义语句（包括建表、修改表结构等（DDL））和更新类事务的提交语句。 

###### **使用场景**

**做全库逻辑备份。**也就是把整库每个表都select出来存成文本。  

###### FTWRL的缺点

* 如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；
* 如果你在从库上备份，那么备份期间从库不能执行主库同步过来的binlog，会导致主从延迟。

为什么加锁？

不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的。 

######  mysqldump 

官方自带的逻辑备份工具是mysqldump。当mysqldump使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。 

**对于全部是InnoDB引擎的库，建议选择使用–single-transaction参数，对应用会更友好**。 

为什么还需要FTWRL呢？

**一致性读是好，但前提是引擎要支持这个隔离级别。**  比如，对于MyISAM这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用FTWRL命令了。 

 所以，**single-transaction方法只适用于所有的表使用事务引擎的库。**  这往往是DBA要求业务开发人员使用InnoDB替代MyISAM的原因之一。 

######  为什么不使用readonly方式？

**既然要全库只读，为什么不使用set global readonly=true的方式呢**？ 

*  在有些系统中，readonly的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改global变量的方式影响面更大，我不建议你使用。 
*  在异常处理机制上有差异。如果执行FTWRL命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为readonly之后，如果客户端发生异常，则数据库就会一直保持readonly状态，这样会导致整个库长时间处于不可写状态，风险较高。 

#### 表锁

MySQL里面表级别的锁有两种： 

###### 表锁

**表锁的语法是 lock tables … read/write。**  与FTWRL类似，可以用unlock tables主动释放锁，也可以在客户端断开的时候自动释放。  

需要注意，**lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。** 

如果在某个线程A中执行lock tables t1 read, t2 write; 这个语句，则其他线程写t1、读写t2的语句都会被阻塞。同时，线程A在执行unlock tables之前，也只能执行读t1、读写t2的操作。连写t1都不允许，自然也不能访问其他表。 

在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于InnoDB这种支持行锁的引擎，一般不使用lock tables命令来控制并发，毕竟锁住整个表的影响面还是太大。 

**表锁一般是在数据库引擎不支持行锁的时候才会被用到的。**如果你发现你的应用程序里有lock tables这样的语句，你需要追查一下，比较可能的情况是： 

* 要么是你的系统现在还在用MyISAM这类不支持事务的引擎，那要安排升级换引擎；
*  要么是你的引擎升级了，但是代码还没升级。 把lock tables 和 unlock tables 改成 begin 和 commit，问题就解决了。 

###### 元数据锁（meta data lock，MDL) 

**MDL不需要显式使用**，在访问一个表的时候会被自动加上。  MDL的作用是，**保证读写的正确性**。  

比如：如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。 

在MySQL 5.5版本中引入了MDL，**当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。** 

*  读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。 
*  读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。 

**事务中的MDL锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。**

**MDL会直到事务提交才释放，在做表结构变更的时候，你一定要小心不要导致锁住线上查询和更新。**  

######  **如何安全地给小表加字段？** 

首先我们要解决长事务，事务不提交，就会一直占着MDL锁。在MySQL的information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做DDL变更的表刚好有长事务在执行，要考虑先**暂停DDL，或者kill掉这个长事务**。 

######  热点表加字段

kill可能未必管用，因为新的请求马上就来了。 比较理想的机制是，在**alter table语句里面设定等待时间**，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者DBA再通过重试命令重复这个过程。 

MariaDB已经合并了AliSQL的这个功能，所以这两个开源分支目前都支持DDL NOWAIT/WAIT n这个语法。 

```
ALTER TABLE tbl_name NOWAIT add column ...
ALTER TABLE tbl_name WAIT N add column ... 
```

#### 行锁

行锁就是针对数据表中行记录的锁 ，比如事务A更新了一行，而这时候事务B也要更新同一行，则必须等事务A的操作完成后才能进行更新。  

**innodb行级锁是通过锁索引记录实现的，如果更新的列没建索引是会锁住整个表的。** 

**并不是所有的引擎都支持行锁，比如MyISAM引擎就不支持行锁 ，这也是MyISAM被InnoDB替代的重要原因之一。**  

不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。 

###### 两阶段锁协议

**在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。** 

 例： 事务B的update语句执行时会是什么现象呢？假设字段id是表t的主键。 ![img](https://static001.geekbang.org/resource/image/51/10/51f501f718e420244b0a2ec2ce858710.jpg) 

事务B的update语句会被阻塞，直到事务A执行commit之后，事务B才能继续执行。 

如何通过减少锁冲突来提升业务并发度？

**如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。** 

###### 死锁

当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无线等待的状态，称为死锁。

 例：![img](https://static001.geekbang.org/resource/image/4d/52/4d0eeec7b136371b79248a0aed005a52.jpg) 

事务A在等待事务B释放id=2的行锁，而事务B在等待事务A释放id=1的行锁。 事务A和事务B在互相等待对方的资源释放，就是进入了死锁状态。 

出现死锁后，有两种解决策略：

1. 第一种策略：直接进入等待，直到超时。这个超时时间可以通过innodb_lock_wait_timeout来设置

   在innoDB中，innodb_locak_wait_timeout默认是50s，意味着当出现死锁后，第一个被锁住的线程要过50s才会超时退出，然后其他线程才有可能继续执行；如果超时时间设置成一个很小的值，会出现很多误伤，比如只是简单的锁等待

2. 第二种策略：发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。

###### 死锁检测

将innodb_deadlock_detect设置为on，表示开启死锁检测。innodb_deadlock_detect默认值就是on。

主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但也**有额外负担**：

每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是个时间复杂度是O(n)的操作。假设有1000个并发线程要同时更新同一行，那么死锁检测操作就是100万这个量级的。虽然最终检测没有死锁，但是这期间要消耗大量的CPU资源。因为会看到**CPU利用率很高，但每秒却执行不了几个事务**。

**怎么解决由这种热点行更新导致的性能问题呢？**  问题的症结在于，死锁检测要耗费大量的CPU资源。 

* **临时把死锁检测关掉** 

  **如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。**  而关掉死锁检测意味着可能会出现大量的超时，**这是业务有损的。** 

*  **控制并发度**

  * **在客户端做并发控制**，但是，你会很快发现这个方法不太可行，因为客户端很多。  

  * **在数据库服务端做并发控制**，如果你有中间件，可以考虑在中间件实现；  **基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了。** 

  * **从设计上优化**

    可以考虑通过将一行改成逻辑上的多行来减少锁冲突。   以影院账户为例，可以考虑放在多条记录上，比如10个记录，影院的账户总额等于这10个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的1/10，可以减少锁等待个数，也就减少了死锁检测的CPU消耗。  **但是业务复杂度可能会大大提高。** 

#### 间隙锁

* 幻读

   幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。 

  注意：

  1.  在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。 
  2. 更新操作，被select语句用“当前读”看到，不能称为幻读。幻读仅专指“新插入的行”。 

*  当前读

   当前读的规则，就是要能读到所有已经提交的记录的最新值 

   加了for update，都是当前读 

* 幻读的问题

   例：![img](https://static001.geekbang.org/resource/image/7a/07/7a9ffa90ac3cc78db6a51ff9b9075607.png) 

  1.   破坏了加锁声明 

     session A where d=5给id=5这一行加了行锁， 并没有给id=0这行加上锁。  session B 可以执行这两条update语句间接的修改了where d=5的值

  2.  发生了数据不一致 

     **即使把所有的记录都加上锁，还是阻止不了新插入的记录** 

* 如何解决幻读？

   产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。  因此，为了解决幻读问题，InnoDB只好引入新的锁，也就是间隙锁(Gap Lock)。 

*  间隙锁 

   间隙锁，锁的就是两个值之间的空隙。 

  ![img](https://static001.geekbang.org/resource/image/e7/61/e7f7ca0d3dab2f48c588d714ee3ac861.png) 

  当执行 select * from t where d=5 for update的时候，就不止是给数据库中已有的6个记录加上了行锁，还同时加了7个间隙锁。这样就确保了无法再插入新的记录。 

   **在一行行扫描的过程中，不仅将给行加上了行锁，还给行两边的空隙，也加上了间隙锁。** 

*  两种类型行锁的冲突关系 

   ![img](https://static001.geekbang.org/resource/image/c4/51/c435c765556c0f3735a6eda0779ff151.png) 

   跟行锁有冲突关系的是“另外一个行锁”。 

*  **间隙锁的冲突关系** 

   **跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。**间隙锁之间都不存在冲突关系。 

  例： ![img](https://static001.geekbang.org/resource/image/7c/98/7c37732d936650f1cda7dbf27daf7498.png) 

  这里session B并不会被堵住。因为表t里并没有c=7这个记录，因此session A加的是间隙锁(5,10)。而session B也是在这个间隙加的间隙锁。**它们有共同的目标，即：保护这个间隙，不允许插入值。但，它们之间是不冲突的。** 

*  next-key lock 

   间隙锁和行锁合称next-key lock，每个next-key lock是前开后闭区间。 

   如果用select * from t for update要把整个表所有记录锁起来，就形成了7个next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +suprenum]。 

   **间隙锁和next-key lock的引入，帮我们解决了幻读的问题** 

* 间隙锁的副作用

   可能会碰到死锁，如：

  ![img](https://static001.geekbang.org/resource/image/df/be/df37bf0bb9f85ea59f0540e24eb6bcbe.png) 

  这个例子， **一旦有并发，就会碰到死锁；如果没有间隙锁就不会出现死锁的现象**

  **即间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的**。 

*  解决幻读的问题 

  如果把隔离级别设置为读提交的话，就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要把binlog格式设置为row。**这也是现在不少公司使用的配置组合**。 

 **如果读提交隔离级别够用，业务不需要可重复读的保证，这样可以考虑读提交隔离级别，读提交下操作数据的锁范围更小（没有间隙锁）** 

####  加锁规则

1. 原则1：加锁的基本单位是next-key lock。希望你还记得，next-key lock是前开后闭区间。
2. 原则2：查找过程中访问到的对象才会加锁。
3. 优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。
4. 优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。
5. 一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。

锁是加在索引上的 ，如果你要用lock in share mode来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，在查询字段中加入索引中不存在的字段 

**在删除数据的时候尽量加limit**。这样不仅可以控制删除数据的条数，让操作更安全，还可以减小加锁的范围。 

在分析加锁规则的时候可以用next-key lock来分析。但具体执行的时候，是要分成间隙锁和行锁两段来执行的。 

可重复读隔离级别遵守两阶段锁协议，所有加锁的资源，都是在事务提交或者回滚的时候才释放的。 

在读提交隔离级别下还有一个优化，即：语句执行过程中加上的行锁，在语句执行完成后，就要把“不满足条件的行”上的行锁直接释放了，不需要等到事务提交。  也就是说，**读提交隔离级别下，锁的范围更小，锁的时间更短，这也是不少业务都默认使用读提交隔离级别的原因**。 

#### 其他锁问题

###### 分析锁问题

* show processlist命令

   需要设置**performance_schema=on**，相比于设置为off会有10%左右的性能损失 

   分析原因的时候，一般都是首先执行一下show processlist命令，看看当前语句处于什么状态。

  ![img](https://static001.geekbang.org/resource/image/50/28/5008d7e9e22be88a9c80916df4f4b328.png)  

*  找出造成阻塞的process id 

  通过查询sys.schema_table_lock_waits这张表，我们就可以直接找出造成阻塞的process id，把这个连接用kill 命令断开即可。 

  ![img](https://static001.geekbang.org/resource/image/74/01/74fb24ba3826e3831eeeff1670990c01.png) 

###### 只查一行的慢查询

* 第一类：查询长时间不返回
  * 等MDL锁

     例：![img](https://static001.geekbang.org/resource/image/74/ca/742249a31b83f4858c51bfe106a5daca.png) 

    session A 通过lock table命令持有表t的MDL写锁，而session B的查询需要获取MDL读锁。所以，session B进入等待状态。

    这类问题的处理方式，就是找到谁持有MDL写锁，然后把它kill掉。

  * 等flush

    flush语句，如果指定表t的话，代表的是只关闭表t；如果没有指定具体的表名，则表示关闭MySQL里所有打开的表。 

    例：

    ![img](https://static001.geekbang.org/resource/image/2b/9c/2bbc77cfdb118b0d9ef3fdd679d0a69c.png) 

     在session A中，我故意每行都调用一次sleep(1)，这样这个语句默认要执行10万秒，在这期间表t一直是被session A“打开”着。然后，session B的flush tables t命令再要去关闭表t，就需要等session A的查询结束。这样，session C要再次查询的话，就会被flush 命令堵住了。 

  * 等行锁

    例： ![img](https://static001.geekbang.org/resource/image/3e/75/3e68326b967701c59770612183277475.png) 

     session A启动了事务，占有写锁，还不提交，是导致session B被堵住的原因。 

    可以通过sys.innodb_lock_waits 表查出是谁占着这个写锁：

    ```
    select * from t sys.innodb_lock_waits where locked_table=`'test'.'t'`\G 
    ```

* 第二类：查询慢

  例：

   ![img](https://static001.geekbang.org/resource/image/84/ff/84667a3449dc846e393142600ee7a2ff.png) 

   ![img](https://static001.geekbang.org/resource/image/1f/1c/1fbb84bb392b6bfa93786fe032690b1c.png) 

  session B更新完100万次，生成了100万个回滚日志(undo log)。 

  带lock in share mode的SQL语句，是当前读，因此会直接读到1000001这个结果，所以速度很快；而select * from t where id=1这个语句，是一致性读，因此需要从1000001开始，依次执行undo log，执行了100万次以后，才将1这个结果返回。 

  ![img](https://static001.geekbang.org/resource/image/46/8c/46bb9f5e27854678bfcaeaf0c3b8a98c.png) 

### 主备

#### 主备切换流程

![img](https://static001.geekbang.org/resource/image/fd/10/fd75a2b37ae6ca709b7f16fe060c2c10.png) 

在状态1中，客户端的读写都直接访问节点A，而节点B是A的备库，只是将A的更新都同步过来，到本地执行。这样可以保持节点B和A的数据是相同的。

当需要切换的时候，就切成状态2。这时候客户端读写访问的都是节点B，而节点A是B的备库。

在状态1中，虽然节点B没有被直接访问，但是依然建议把节点B（也就是备库）设置成只读（readonly）模式：

1. 有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以**防止误操作**；
2. **防止切换逻辑有bug**，比如切换过程中出现双写，造成主备不一致；
3. 可以用readonly状态，来**判断节点的角色**

 把备库设置成只读了，还怎么跟主库保持同步更新呢？ 

 为readonly设置对超级(super)权限用户是无效的，而用于同步更新的线程，就拥有超级权限。 

######  主备切换的策略

![img](https://static001.geekbang.org/resource/image/89/cc/89290bbcf454ff9a3dc5de42a85a69cc.png) 

* 可靠性优先策略

   双M结构下，从状态1到状态2切换的过程：

  1.  判断备库B现在的seconds_behind_master，如果小于某个值（比如5秒）继续下一步，否则持续重试这一步； 
  2.  把主库A改成只读状态，即把readonly设置为true； 
  3.  判断备库B的seconds_behind_master的值，直到这个值变成0为止； 
  4.  把备库B改成可读写状态，也就是把readonly 设置为false； 
  5.  把业务请求切到备库B。 

  这个切换流程中是有不可用时间的。因为在步骤2之后，主库A和备库B都处于readonly状态，也就是说这时系统处于不可写状态，直到步骤5完成后才能恢复。 

  在这个不可用状态中，**比较耗费时间的是步骤3，可能需要耗费好几秒的时间。这也是为什么需要在步骤1先做判断，确保seconds_behind_master的值足够小。** 

  试想如果一开始主备延迟就长达30分钟，而不先做判断直接切换的话，系统的不可用时间就会长达30分钟 

* 可用性优先策略

  如果强行把步骤4、5调整到最开始执行，也就是说**不等主备数据同步，直接把连接切到备库B，并且让备库B可以读写，那么系统几乎就没有不可用时间了。** 

  这个切换流程的代价，就是**可能出现数据不一致的情况**。  **建议使用可靠性优先策略**。毕竟对数据服务来说的话，数据的可靠性一般还是要优于可用性的。 

   **有没有哪种情况数据的可用性优先级更高呢？** 有

   这样的一个场景： 

  - 有一个库的作用是记录操作日志。这时候，如果数据不一致可以通过binlog来修补，而这个短暂的不一致也不会引发业务问题。
  - 同时，业务系统依赖于这个日志写入逻辑，如果这个库不可写，会导致线上的业务操作无法执行。

   这时候，你可能就需要选择先强行切换，事后再补数据的策略。 

在满足数据可靠性的前提下，**MySQL高可用系统的可用性，是依赖于主备延迟的**。延迟的时间越小，在主库故障的时候，服务恢复需要的时间就越短，可用性就越高。 

#### 主备同步流程

![img](https://static001.geekbang.org/resource/image/a6/a3/a66c154c1bc51e071dd2cc8c1d6ca6a3.png) 

备库B跟主库A之间维持了一个长连接。主库A内部有一个线程，专门用于服务备库B的这个长连接。 

主备同步的流程：

1. 在备库B上通过change master命令，设置主库A的IP、端口、用户名、密码，以及要从哪个位置开始请求binlog，这个位置包含文件名和日志偏移量。
2. 在备库B上执行start slave命令，这时候备库会启动两个线程，就是图中的io_thread和sql_thread。其中io_thread负责与主库建立连接。
3. 主库A校验完用户名、密码后，开始按照备库B传过来的位置，从本地读取binlog，发给B。
4. 备库B拿到binlog后，写到本地文件，称为中转日志（relay log）。
5. sql_thread读取中转日志，解析出日志里的命令，并执行。

###### 循环复制问题

双M结构：

![img](https://static001.geekbang.org/resource/image/20/56/20ad4e163115198dc6cf372d5116c956.png) 

业务逻辑在节点A上更新了一条语句，然后再把生成的binlog 发给节点B，节点B执行完这条更新语句后也会生成binlog。（建议把参数log_slave_updates设置为on，表示备库执行relay log后生成binlog）。 

如果节点A同时是节点B的备库，相当于又把节点B新生成的binlog拿过来执行了一次，然后节点A和B间，会不断地循环执行这个更新语句，也就是循环复制了。 

 这个要怎么解决呢？ 

 MySQL在binlog中记录了这个命令第一次执行时所在实例的server id ，因此可以用下面的逻辑，来解决两个节点间的循环复制的问题： 

1.  规定两个库的server id必须不同，如果相同，则它们之间不能设定为主备关系； 
2.  一个备库接到binlog并在重放的过程中，生成与原binlog的server id相同的新的binlog； 
3.  每个库在收到从自己的主库发过来的日志后，先判断server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。 

 如果设置了双M结构，日志的执行流就会变成这样： 

1.  从节点A更新的事务，binlog里面记的都是A的server id； 
2.  传到节点B执行一次以后，节点B生成的binlog 的server id也是A的server id； 
3.  再传回给节点A，A判断到这个server id与自己的相同，就不会再处理这个日志。所以，死循环在这里就断掉了。 

#### 主备延迟

 主备切换可能是一个**主动运维**动作，比如**软件升级、主库所在机器按计划下线等**，也可能是**被动操作**，比如**主库所在机器掉电**。 

######  同步延迟

 数据同步有关的时间点：

1. 主库A执行完成一个事务，写入binlog，我们把这个时刻记为T1;
2. 之后传给备库B，我们把备库B接收完这个binlog的时刻记为T2;
3. 备库B执行完成这个事务，我们把这个时刻记为T3。

 所谓主备延迟，就是**同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值**，也就是T3-T1。 

* seconds_behind_master

  可以在备库上执行show slave status命令，它的返回结果里面会显示seconds_behind_master，用于表示当前备库延迟了多少秒。 

主备库机器的系统时间设置不一致，会不会导致主备延迟的值不准？ 

不会的。因为备库连接到主库的时候，会通过执行SELECT UNIX_TIMESTAMP()函数来获得当前主库的系统时间。如果这时候发现主库的系统时间与自己不一致，备库在执行seconds_behind_master计算的时候会自动扣掉这个差值。 

需要说明的是，在网络正常的时候，日志从主库传给备库所需的时间是很短的。 网络正常情况下，**主备延迟的主要来源是备库接收完binlog和执行完这个事务之间的时间差**。 

主备延迟最直接的表现是，**备库消费中转日志（relay log）的速度，比主库生产binlog的速度要慢。** 

###### 主备延迟的来源

- **有些部署条件下，备库所在机器的性能要比主库所在的机器性能差。**  

  反正备库没有请求，所以可以用差一点儿的机器。 更新过程中也会触发大量的读操作。所以，当备库主机上的多个备库都在争抢资源的时候，就可能会导致主备延迟了。 

  因为主备可能发生切换，备库随时可能变成主库，所以主备库选用相同规格的机器，并且做对称部署，是现在比较常见的情况。 

- **备库的压力大**

   **做了对称部署以后，还可能会有延迟**。这是为什么呢？ 

  主库既然提供了写能力，那么备库可以提供一些读能力。 或者一些运营后台需要的分析语句，不能影响正常业务，只能在备库上跑。 **由于主库直接影响业务，大家使用起来会比较克制，反而忽视了备库的压力控制**。结果就是，备库上的查询耗费了大量的CPU资源，影响了同步速度，造成主备延迟。 

  解决方法：

  1.  一主多从
  2. 通过binlog输出到外部系统，比如Hadoop这类系统，让外部系统提供统计类查询的能力。 

  其中，**一主多从的方式大都会被采用**。因为作为数据库系统，还必须保证有定期全量备份的能力。而从库，就很适合用来做备份。 

- **大事务**  

  采用了一主多从，保证备库的压力不会超过主库，还有什么情况可能导致主备延迟吗？ 

  因为主库上必须等事务执行完成才会写入binlog，再传给备库。所以，如果一个主库上的语句执行10分钟，那这个事务很可能就会导致从库延迟10分钟。 

  * 不要**一次性地用delete语句删除太多数据**。其实，这就是一个典型的大事务场景。 

  *  **另一种典型的大事务场景，就是大表DDL** 

     处理方案就是，计划内的DDL，建议使用gh-ost方案 

-  **备库的并行复制能力** 

   如果主库上也不做大事务了，还有什么原因会导致主备延迟吗？ 

   造成主备延迟还有一个大方向的原因，就是**备库的并行复制能力**。 

####  GTID

![img](https://static001.geekbang.org/resource/image/aa/79/aadb3b956d1ffc13ac46515a7d619e79.png) 

 A和A’互为主备， 从库B、C、D指向的是主库A。 

 一主多从的设置，一般用于读写分离，主库负责所有的写入和一部分读，其他的读请求则由从库分担。 

 在一主多从架构下，主库故障后的主备切换后的结果：

![img](https://static001.geekbang.org/resource/image/00/53/0014f97423bd75235a9187f492fb2453.png) 

 一主多从结构在切换完成后，A’会成为新的主库，从库B、C、D也要改接到A’。正是由于多了从库B、C、D重新指向的这个过程，所以主备切换的复杂性也相应增加了。 

###### 基于位点的主备切换

 当我们把节点B设置成节点A’的从库的时候，需要执行一条change master命令： 

```
CHANGE MASTER TO 
MASTER_HOST=$host_name 
MASTER_PORT=$port 
MASTER_USER=$user_name 
MASTER_PASSWORD=$password 
MASTER_LOG_FILE=$master_log_name 
MASTER_LOG_POS=$master_log_pos  
```

最后两个参数MASTER_LOG_FILE和MASTER_LOG_POS表示，要从主库的master_log_name文件的master_log_pos这个位置的日志继续同步。而**这个位置就是我们所说的同步位点，也就是主库对应的文件名和日志偏移量。**

但是这两个参数到底应该怎么设置呢？ 

**原来节点B是A的从库，本地记录的也是A的位点。但是相同的日志，A的位点和A’的位点是不同的。因此，从库B要切换的时候，就需要先经过“找同步位点”这个逻辑。** 

 这个位点很难精确取到，只能取一个大概位置。 

 考虑到切换过程中不能丢数据，所以我们找位点的时候，总是要找一个“稍微往前”的，然后再通过判断跳过那些在从库B上已经执行过的事务。 

 一种取同步位点的方法：

1. 等待新主库A’把中转日志（relay log）全部同步完成；
2. 在A’上执行show master status命令，得到当前A’上最新的File 和 Position；
3. 取原主库A故障的时刻T；
4. 用mysqlbinlog工具解析A’的File，得到T时刻的位点。

```
mysqlbinlog File --stop-datetime=T --start-datetime=T
```

*  **主动跳过这些错误，有两种常用的方法**：

  1.  主动跳过一个事务 

     ```
     set global sql_slave_skip_counter=1;
     start slave;
     ```

     因为切换过程中，可能会不止重复执行一个事务，所以我们需要在从库B刚开始接到新主库A’时，持续观察，每次碰到这些错误就停下来，执行一次跳过命令，直到不再出现停下来的情况，以此来跳过可能涉及的所有事务。 

  2.  通过设置slave_skip_errors参数，直接设置跳过指定的错误。 

     在执行主备切换时，有这么两类错误，是经常会遇到的：

     - 1062错误是插入数据时唯一键冲突；
     - 1032错误是删除数据时找不到行。

      可以把slave_skip_errors 设置为 “1032,1062”，这样中间碰到这两个错误时就直接跳过。 

###### GTID

通过sql_slave_skip_counter跳过事务和通过slave_skip_errors忽略错误的方法，这两种操作都很复杂，而且容易出错。所以，MySQL 5.6版本引入了GTID，彻底解决了这个困难。 

GTID的全称是Global Transaction Identifier，也就是**全局事务ID，是一个事务在提交的时候生成的**，是这个事务的唯一标识。它由两部分组成，格式是： 

```
GTID=server_uuid:gno
```

- server_uuid是一个实例第一次启动时自动生成的，是一个全局唯一的值；
- gno是一个整数，初始值是1，每次提交事务的时候分配给这个事务，并加1

 **GTID是连续的** 

*  GTID模式的启动：

   只需要在启动一个MySQL实例的时候，加上参数gtid_mode=on和enforce_gtid_consistency=on就可以了。 

*  GTID有两种生成方式，而使用哪种方式取决于session变量gtid_next的值：

  *  如果gtid_next=automatic，代表使用默认值。这时，MySQL就会把server_uuid:gno分配给这个事务。 
    1.  记录binlog的时候，先记录一行 SET @@SESSION.GTID_NEXT=‘server_uuid:gno’; 
    2.  把这个GTID加入本实例的GTID集合。 
  *  如果gtid_next是一个指定的GTID的值，比如通过set gtid_next='current_gtid’指定为current_gtid，那么就有两种可能： 
    1.  如果current_gtid已经存在于实例的GTID集合中，接下来执行的这个事务会直接被系统忽略； 
    2.  如果current_gtid没有存在于实例的GTID集合中，就将这个current_gtid分配给接下来要执行的事务，也就是说系统不需要给这个事务生成新的GTID，因此gno也不用加1。 

注意，**一个current_gtid只能给一个事务使用**。这个事务提交后，如果要执行下一个事务，就要执行set 命令，把gtid_next设置成另外一个gtid或者automatic。 

例： 实例X作为Y的从库，同步事务的时候，出现主键冲突，导致实例X的同步线程停止。这时应该怎么处理呢？ 

```
set gtid_next='aaaaaaaa-cccc-dddd-eeee-ffffffffffff:10';
begin;
commit;
set gtid_next=automatic;
start slave;
```

前三条语句的作用，是通过提交一个空事务，把这个GTID加到实例X的GTID集合中。  再执行start slave命令让同步线程执行起来的时候，虽然实例X上还是会继续执行实例Y传过来的事务，但是由于 “aaaaaaaa-cccc-dddd-eeee-ffffffffffff:10”已经存在于实例X的GTID集合中了，所以实例X就会**直接跳过这个事务**，也就**不会再出现主键冲突**的错误。  

###### 基于GTID的主备切换

在GTID模式下，备库B要设置为新主库A’的从库的语法如下： 

```
CHANGE MASTER TO 
MASTER_HOST=$host_name 
MASTER_PORT=$port 
MASTER_USER=$user_name 
MASTER_PASSWORD=$password 
master_auto_position=1 
```

**master_auto_position=1就表示这个主备关系使用的是GTID协议。**  前面让我们头疼不已的MASTER_LOG_FILE和MASTER_LOG_POS参数，已经不需要指定了。 

主备复制逻辑：

在实例B上执行start slave命令，取binlog的逻辑是这样的： 

1. 实例B指定主库A’，基于主备协议建立连接。  
2.  实例B把set_b发给主库A’。 
3.  实例A’算出set_a与set_b的差集，也就是所有存在于set_a，但是不存在于set_b的GITD的集合，判断A’本地是否包含了这个差集需要的所有binlog事务。 
   *  如果不包含，表示A’已经把实例B需要的binlog给删掉了，直接返回错误； 
   *  如果确认全部包含，A’从自己的binlog文件里面，找出第一个不在set_b的事务，发给B； 
4.  之后就从这个事务开始，往后读文件，按顺序取binlog发给B去执行。 

**在基于GTID的主备关系里，系统认为只要建立主备关系，就必须保证主库发给备库的日志是完整的。**因此，如果实例B需要的日志已经不存在，A’就拒绝把日志发给B。 

这跟基于位点的主备协议不同。基于位点的协议，是由备库决定的，备库指定哪个位点，主库就发哪个位点，不做日志的完整性判断。 

######  一主多从的主备切换  

由于不需要找位点了，所以从库B、C、D只需要分别执行change master命令指向实例A’即可。 

严谨地说，主备切换不是不需要找位点了，而是找位点这个工作，在实例A’内部就已经自动完成了。 

之后这个系统就由新主库A’写入，主库A’的自己生成的binlog中的GTID集合格式是：server_uuid_of_A’:1-M。

如果之前从库B的GTID集合格式是 server_uuid_of_A:1-N， 那么切换之后GTID集合的格式就变成了server_uuid_of_A:1-N, server_uuid_of_A’:1-M。

当然，主库A’之前也是A的备库，因此主库A’和从库B的GTID集合是一样的。

###### GTID和在线DDL

在双M结构下，备库执行的DDL语句也会传给主库，为了避免传回后对主库造成影响，要通过set sql_log_bin=off关掉binlog。  这样操作的话，数据库里面是加了索引，但是binlog并没有记录下这一个更新，  会导致数据和日志不一致。

假设，这两个互为主备关系的库还是实例X和实例Y，且当前主库是X，并且都打开了GTID模式。这时的主备切换流程可以变成下面这样： 

1.  在实例X上执行stop slave。 

2.  在实例Y上执行DDL语句。注意，这里并不需要关闭binlog。 

3.  执行完成后，查出这个DDL语句对应的GTID，并记为 server_uuid_of_Y:gno。 

4.  到实例X上执行以下语句序列： 

   ```
   set GTID_NEXT="server_uuid_of_Y:gno";
   begin;
   commit;
   set gtid_next=automatic;
   start slave;
   ```

   这样做的目的在于，既可以让实例Y的更新有binlog记录，同时也可以确保不会在实例X上执行这条更新。 

5. 接下来，执行完主备切换，然后照着上述流程再执行一遍即可。

**如果你使用的MySQL版本支持GTID的话，都建议你尽量使用GTID模式来做一主多从的切换。** 

### 其他

#### count(*)

###### count(*)的实现方式 

在不同的MySQL引擎中，count(*)有不同的实现方式：

* MyISAM引擎把一个表的总行数存在了磁盘上，因此执行count(*)的时候会直接返回这个数，效率很高；
* 而InnoDB引擎就麻烦了，它执行count(*)的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。

 **这里是没有过滤条件的count(*)，如果加了where 条件的话，MyISAM表也是不能返回得这么快的** 

**为什么InnoDB不跟MyISAM一样，也把数字存起来呢？** 

**这是因为即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB表“应该返回多少行”也是不确定的。** 

这和InnoDB的事务设计有关系，可重复读是它默认的隔离级别，在代码上就是通过多版本并发控制，也就是MVCC来实现的。每一行记录都要判断自己是否对这个会话可见，因此对于count(*)请求来说，InnoDB只好把数据一行一行地读出依次判断，可见的行才能够用于计算“基于这个查询”的表的总行数。 

InnoDB引擎的count(*)操作还是做了优化的：

对于count(*)这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL优化器会找到最小的那棵树来遍历( InnoDB是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多 )。 

**在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。** 

TABLE_ROWS为什么不能代替count(*) ？

索引统计的值是通过采样来估算的。实际上，TABLE_ROWS就是从这个采样估算得来的，因此它也很不准。  **所以，show table status命令显示的行数也不能直接使用。** 

- MyISAM表虽然count(*)很快，但是不支持事务；
- show table status命令虽然返回很快，但是不准确；
- InnoDB表直接count(*)会遍历全表，虽然结果准确，但会导致性能问题。

###### 自己计数来统计表行数

* 用缓存系统保存计数

  用缓存系统保存计数有丢失数据和计数不精确的问题。 

  把计数放在Redis里面，不能够保证计数和MySQL表里的数据精确一致的原因，是**这两个不同的存储构成的系统，不支持分布式事务，无法拿到精确一致的视图。**而把计数值也放在MySQL中，就解决了一致性视图的问题。 

* 在数据库保存计数

   **把这个计数直接放到数据库里单独的一张计数表中** 

###### 不同的count用法

count(*)、count(主键id)、count(字段)和count(1)等不同用法的性能有哪些差别？

*  count()的语义

  count()是一个聚合函数，**对于返回的结果集，一行行地判断，如果count函数的参数不是NULL，累计值就加1** 

  count(*)、count(主键id)和count(1) 都表示返回满足条件的结果集的总行数；而count(字段），则表示返回满足条件的数据行里面，参数“字段”不为NULL的总个数。 

*  分析性能差别的几个原则

  1.  server层要什么就给什么； 
  2.  InnoDB只给必要的值； 
  3.  现在的优化器只优化了count(*)的语义为“取行数”，其他“显而易见”的优化并没有做。 

**对于count(主键id)来说**，InnoDB引擎会遍历整张表，把每一行的id值都取出来，返回给server层。server层拿到id后，判断是不可能为空的，就按行累加。

**对于count(1)来说**，InnoDB引擎遍历整张表，但不取值。server层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。

所以count(1)执行得要比count(主键id)快。因为从引擎返回id会涉及到解析数据行，以及拷贝字段值的操作。 

**对于count(字段)来说**：

1. 如果这个“字段”是定义为not null的话，一行行地从记录里面读出这个字段，判断不能为null，按行累加；
2. 如果这个“字段”定义允许为null，那么执行的时候，判断到有可能是null，还要把值取出来再判断一下，不是null才累加。

 **count(\*)是例外**，并不会把全部字段取出来，而是专门做了优化，不取值。count(*)肯定不是null，按行累加。 

 按照效率排序的话，count(字段)<count(主键id)<count(1)≈count(\*)，所以建议**尽量使用count(\*)**。 

#### order by

例： select city,name,age from t where city='杭州' order by name limit 1000  ; 

###### 全字段排序

Extra这个字段中的“Using filesort”表示的就是需要排序，MySQL会给每个线程分配一块内存用于排序，称为sort_buffer。 

这个语句执行流程如下所示 ： 

1. 初始化sort_buffer，确定放入city,name,age这三个字段
2. 从索引city找到第一个满足city='杭州'条件的主键id
3. 到主键id索引取出整行，取出city,name,age这三个字段的值，存入sort_buffer中
4. 从索引city取下一个记录的主键id
5. 重复步骤3、4直到city的值不满足查询条件为止
6. 对sort_buffer中的数据按照字段name做快速排序
7. 按照排序结果取出1000行返回给客户端

![img](https://static001.geekbang.org/resource/image/6c/72/6c821828cddf46670f9d56e126e3e772.jpg) 

* sort_buffer_size

  “按name排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数sort_buffer_size。

  sort_buffer_size就是MySQL为排序开辟的内存(sort_buffer)大小。

  **如果要排序的数据量小于sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序**

* number_of_tmp_files 

  用下面的方法，来确定一个排序语句是否使用了临时文件。 

  ```
  /* 打开optimizer_trace，只对本线程有效 */
  SET optimizer_trace='enabled=on'; 
  
  /* @a保存Innodb_rows_read的初始值 */
  select VARIABLE_VALUE into @a from  performance_schema.session_status where variable_name = 'Innodb_rows_read';
  
  /* 执行语句 */
  select city, name,age from t where city='杭州' order by name limit 1000; 
  
  /* 查看 OPTIMIZER_TRACE 输出 */
  SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G
  
  /* @b保存Innodb_rows_read的当前值 */
  select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = 'Innodb_rows_read';
  
  /* 计算Innodb_rows_read差值 */
  select @b-@a;
  ```

  这个方法是通过查看 OPTIMIZER_TRACE 的结果来确认的，你可以从 number_of_tmp_files中看到是否使用了临时文件。 

  ![img](https://static001.geekbang.org/resource/image/89/95/89baf99cdeefe90a22370e1d6f5e6495.png)

​	**number_of_tmp_files表示的是，排序过程中使用的临时文件数。**

​	examined_rows=4000，表示参与排序的行数是4000行。  

​	为什么需要12个文件这么多？ 

​	内存放不下时，就需要使用外部排序，外部排序一般使用归并排序算法。可以这么简单理解，**MySQL将需要排	序的数据分成12份，每一份单独排序后存在这些临时文件中。然后把这12个有序文件再合并成一个有序的大文	件。** 

​	如果sort_buffer_size超过了需要排序的数据量的大小，number_of_tmp_files就是0，表示排序可以直接在内存	中完成。否则就需放在临时文件中排序。sort_buffer_size越小，需要分成的份数越多，number_of_tmp_files	的值就越大。

###### **rowid排序**

全字段排序有一个问题，**如果查询要返回的字段很多的话，那么sort_buffer里面要放的字段太多，这样内存里能够同时放下的行数就很少，要分成很多个临时文件，排序的性能会很差。**

**如果MySQL认为排序的单行长度太大会怎么做呢？** 

max_length_for_sort_data，是MySQL中专门控制用于排序的行数据的长度的参数。它的意思是，如果单行的长度超过这个值，MySQL就认为单行太大，要换成rowid排序算法。

如 city、name、age 这三个字段的定义总长度是36，把max_length_for_sort_data设置为16， MySQL则会使用rowid排序算法：放入sort_buffer的字段，只有要排序的列(即name字段)和主键id。但排序的结果因为少了city和age字段的值，不能直接返回了，执行流程变为下面这样：

1. 初始化sort_buffer，确定放入两个字段，即name和id
2. 从索引city找到第一个满足city='杭州'条件的主键id
3. 到主键id索引取出整行，取name、id这两个字段，存入sort_buffer
4. 从索引city取下一个记录的主键id
5. 重复步骤3、4直到不满足city='杭州'条件为止
6. 对sort_buffer中的数据按照字段name进行排序
7. 遍历排序结果，取前1000行，并按照id的值回到原表取出city、name和age三个字段返回给客户端

![img](https://static001.geekbang.org/resource/image/dc/6d/dc92b67721171206a302eb679c83e86d.jpg) 

 ![img](https://static001.geekbang.org/resource/image/27/9b/27f164804d1a4689718291be5d10f89b.png) 

图中的examined_rows的值还是4000，表示用于排序的数据是4000行。但是select @b-@a这个语句的值变成5000了。

因为这时候除了排序过程外，在排序完成后，还要根据id去原表取值。由于语句是limit 1000，因此会多读1000行。

从OPTIMIZER_TRACE的结果中，你还能看到另外两个信息也变了：

- sort_mode变成了<sort_key, rowid>，表示参与排序的只有name和id这两个字段。
- number_of_tmp_files变成10了，是因为这时候参与排序的行数虽然仍然是4000行，但是每一行都变小了，因此需要排序的总数据量就变小了，需要的临时文件也相应地变少了。

###### 全字段排序 VS rowid排序

**如果MySQL实在是担心排序内存太小，会影响排序效率，才会采用rowid排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。** 

**如果MySQL认为内存足够大，会优先选择全字段排序，把需要的字段都放到sort_buffer中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。** 

这也就体现了MySQL的一个设计思想：**如果内存够，就要多利用内存，尽量减少磁盘访问。** 

对于InnoDB表来说，**rowid排序会要求回表多造成磁盘读，因此不会被优先选择**。 

所有的order by都需要排序吗？ 

MySQL之所以需要生成临时表，并且在临时表上做排序操作，**其原因是原来的数据都是无序的。**  如果能够保证从city这个索引上取出来的行，天然就是按照name递增排序的话，就可以不用再排序了。

可以在这个市民表上创建一个city和name的联合索引，对应的SQL语句是： 

```
alter table t add index city_user(city, name);
```

![img](https://static001.geekbang.org/resource/image/f9/bf/f980201372b676893647fb17fac4e2bf.png) 

在这个索引里面，只要city的值是杭州，name的值就一定是有序的。 

这样整个查询过程的流程就变成了： 

1.  从索引(city,name)找到第一个满足city='杭州’条件的主键id； 
2.  到主键id索引取出整行，取name、city、age三个字段的值，作为结果集的一部分直接返回 
3.  从索引(city,name)取下一个记录主键id； 
4.  重复步骤2、3，直到查到第1000条记录，或者是不满足city='杭州’条件时循环结束。 

![img](https://static001.geekbang.org/resource/image/3f/92/3f590c3a14f9236f2d8e1e2cb9686692.jpg) 

![img](https://static001.geekbang.org/resource/image/fc/8a/fc53de303811ba3c46d344595743358a.png) 

Extra字段中没有Using filesort了，也就是不需要排序了。而且由于(city,name)这个联合索引本身有序，所以这个查询也不用把4000行全都读一遍，只要找到满足条件的前1000条记录就可以退出了。 

**这个语句的执行流程其实可以进一步简化** 

可以创建一个city、name和age的联合索引，对应的SQL语句就是： 

```
alter table t add index city_user_age(city, name, age);
```

整个查询语句的执行流程就变成了： 

1. 从索引(city,name,age)找到第一个满足city='杭州’条件的记录，取出其中的city、name和age这三个字段的值，作为结果集的一部分直接返回；
2.  从索引(city,name,age)取下一个记录，同样取出这三个字段的值，作为结果集的一部分直接返回； 
3.  重复执行步骤2，直到查到第1000条记录，或者是不满足city='杭州’条件时循环结束。  

![img](https://static001.geekbang.org/resource/image/df/d6/df4b8e445a59c53df1f2e0f115f02cd6.jpg) 

![img](https://static001.geekbang.org/resource/image/9e/23/9e40b7b8f0e3f81126a9171cc22e3423.png) 

Extra字段里面多了“Using index”，表示的就是使用了覆盖索引，性能上会快很多。 

并不是说要为了每个查询能用上覆盖索引，就要把语句中涉及的字段都建上联合索引，毕竟索引还是有维护代价的。这是一个需要权衡的决定。 

######  随机排序

直接使用order by rand()，这个语句需要Using temporary 和 Using filesort ，查询的执行代价往往是比较大的。所以，**在设计的时候你要量避开这种写法**。  

* rowid

   它表示的是：每个引擎用来唯一标识数据行的信息。 

  - 对于有主键的InnoDB表来说，这个rowid就是主键ID；
  - 对于没有主键的InnoDB表来说，这个rowid就是由系统生成的；
  - MEMORY引擎不是索引组织表。**可以认为它就是一个数组**。因此，这个**rowid其实就是数组的下标**。

*  **order by rand()使用了内存临时表，内存临时表排序的时候使用了rowid排序方法。** 

* memory引擎使用rowid排序 

   **对于InnoDB表来说**，执行全字段排序会减少磁盘访问，因此会被优先选择。 

   **对于内存表，回表过程只是简单地根据数据行的位置，直接访问内存得到数据，根本不会导致多访问磁盘**。  就是用于排序的行越少越好了，所以，MySQL这时就会选择rowid排序。 

*  memory引擎排序流程 

  1. 创建一个临时表。这个临时表使用的是memory引擎，表里有两个字段，第一个字段是double类型，为了后面描述方便，记为字段R，第二个字段是varchar(64)类型，记为字段W。并且，这个表没有建索引。 
  2.  从words表中，按主键顺序取出所有的word值。对于每一个word值，调用rand()函数生成一个大于0小于1的随机小数，并把这个随机小数和word分别存入临时表的R和W字段中，到此，扫描行数是10000。 
  3.  初始化 sort_buffer。sort_buffer中有两个字段，一个是double类型，另一个是整型。 
  4.  从内存临时表中一行一行地取出R值和位置信息 ，分别存入sort_buffer中的两个字段里。这个过程要对内存临时表做全表扫描，此时扫描行数增加10000，变成了20000。 
  5.  在sort_buffer中根据R的值进行排序。注意，这个过程没有涉及到表操作，所以不会增加扫描行数。 
  6.  排序完成后，取出前三个结果的位置信息，依次到内存临时表中取出word值，返回给客户端。这个过程中，访问了表的三行数据，总扫描行数变成了20003。 

  ![img](https://static001.geekbang.org/resource/image/2a/fc/2abe849faa7dcad0189b61238b849ffc.png) 

* 磁盘临时表

   是不是所有的临时表都是内存表呢？ 

   不是的。tmp_table_size这个配置限制了内存临时表的大小，默认值是16M。**如果临时表大小超过了tmp_table_size**，那么内存临时表就会转成磁盘临时表。 

  * 磁盘临时表使用的引擎默认是InnoDB，是由参数internal_tmp_disk_storage_engine控制的。 
  *  当使用磁盘临时表的时候，对应的就是一个没有显式索引的InnoDB表的排序过程。 

*  优先队列排序算法 

   比如只需要取R值最小的3个rowid。但是，如果使用归并排序算法的话，虽然最终也能得到前3个值，但是这个算法结束后，已经将10000行数据都排好序了。

  *  优先队列排序算法执行流程 

    1. 对于这10000个准备排序的(R,rowid)，先取前三行，构造成一个堆；
    2.  取下一个行(R’,rowid’)，跟当前堆里面最大的R比较，如果R’小于R，把这个(R,rowid)从堆中去掉，换成(R’,rowid’)； 
    3.  重复第2步，直到第10000个(R’,rowid’)完成比较。 

    这个流程结束后，我们构造的堆里面，就是这个10000行里面R值最小的三行。然后，依次把它们的rowid取出来，去临时表里面拿到word字段 

    **filesort_priority_queue_optimization这个部分的chosen=true，就表示使用了优先队列排序算法，这个过程不需要临时文件，因此对应的number_of_tmp_files是0。** 

*  limit 1000  为什么没用优先队列排序算法呢？ 

   如果使用优先队列算法的话，需要维护的堆的大小就是1000行的(name,rowid)，超过了我设置的sort_buffer_size大小，所以只能使用归并排序算法。 

* 随机排序方法

  1.  取得整个表的行数，并记为C。 
  2.  取得 Y = floor(C * rand())。 floor函数在这里的作用，就是取整数部分。 
  3.  再用limit Y,1 取得一行。 

  ```
  mysql> select count(*) into @C from t;
  set @Y1 = floor(@C * rand());
  set @Y2 = floor(@C * rand());
  set @Y3 = floor(@C * rand());
  select * from t limit @Y1，1； //在应用代码里面取Y1、Y2、Y3值，拼出SQL后执行
  select * from t limit @Y2，1；
  select * from t limit @Y3，1；
  ```

#### Join语句

###### Index Nested-Loop Join(**NLJ**)

例： select * from t1 straight_join t2 on (t1.a=t2.a); 

语句执行流程：

1. 从表t1中读入一行数据 R；
2. 从数据行R中，取出a字段到表t2里去查找；
3. 取出表t2中满足条件的行，跟R组成一行，作为结果集的一部分；
4. 重复执行步骤1到3，直到表t1的末尾循环结束。

这个过程是先遍历表t1，然后根据从表t1中取出的每行数据中的a值，去表t2中查找满足条件的记录。在形式上，这个过程就跟我们写程序时的嵌套查询类似，并且可以用上被驱动表的索引，所以我们称之为“Index Nested-Loop Join”，简称**NLJ**。 

单表查询实现方式：

1. 执行`select * from t1`，查出表t1的所有数据，这里有100行；
2. 循环遍历这100行数据：
   - 从每一行R取出字段a的值$R.a；
   - 执行`select * from t2 where a=$R.a`；
   - 把返回的结果和R构成结果集的一行。

在这个查询过程，**也是扫描了200行**，但是总共执行了101条语句，**比直接join多了100次交互**。除此之外，客户端还要自己拼接SQL语句和结果。  显然，这么做**还不如直接join好**。 

**“可以使用被驱动表的索引”  的前提下**：

1. 使用join语句，性能比强行拆成多个单表执行SQL语句的性能要好； 
2.  如果使用join语句的话，需要让小表做驱动表。 

###### Block Nested-Loop Join (BNL) 

被驱动表上没有可用的索引，算法的流程是这样的： 

1. 把表t1的数据读入线程内存join_buffer中，由于我们这个语句中写的是select *，因此是把整个表t1放入了内存；
2. 扫描表t2，把表t2中的每一行取出来，跟join_buffer中的数据做对比，满足join条件的，作为结果集的一部分返回。

*  join_buffer_size 

  join_buffer的大小是由参数join_buffer_size设定的，默认值是256k。**如果放不下表t1的所有数据话，策略很简单，就是分段放。** 

  执行过程就变成了： 

  1. 扫描表t1，顺序读取数据行放入join_buffer中，放完第88行join_buffer满了，继续第2步；
  2. 扫描表t2，把t2中的每一行取出来，跟join_buffer中的数据做对比，满足join条件的，作为结果集的一部分返回；
  3. 清空join_buffer；
  4. 继续扫描表t1，顺序读取最后的12行数据放入join_buffer中，继续执行第2步。

  ![img](https://static001.geekbang.org/resource/image/69/c4/695adf810fcdb07e393467bcfd2f6ac4.jpg) 

   这个流程才体现出了这个算法名字中“Block”的由来，表示**“分块去join”**。 

   这时候由于表t1被分成了两次放入join_buffer中，导致表t2会被扫描两次。 

   **如果你的join语句很慢，就把join_buffer_size改大。** 

*  能不能使用join语句？ 

  1. 如果可以使用Index Nested-Loop Join算法，也就是说可以用上被驱动表上的索引，其实是没问题的；
  2. 如果使用Block Nested-Loop Join算法，扫描行数就会过多。尤其是在大表上的join操作，这样可能要扫描被驱动表很多次，会占用大量的系统资源。所以**这种join尽量不要用。**

  在判断要不要使用join语句时，就是看explain结果里面，**Extra字段里面有没有出现“Block Nested Loop”字样**。 

*  如果要使用join，应该选择大表做驱动表还是选择小表做驱动表？ 

  1.  如果是Index Nested-Loop Join算法，应该选择小表做驱动表； 
  2. 如果是Block Nested-Loop Join算法：
     - 在join_buffer_size足够大的时候，是一样的；
     - 在join_buffer_size不够大的时候（这种情况更常见），应该选择小表做驱动表。

   **总是应该使用小表做驱动表**。 

*  **什么叫作“小表” ？**

  例1：

  ```
  select * from t1 straight_join t2 on (t1.b=t2.b) where t2.id<=50;
  select * from t2 straight_join t1 on (t1.b=t2.b) where t2.id<=50;
  ```

  如果是用第二个语句的话，join_buffer只需要放入t2的前50行，显然是更好的。所以 “t2的前50行”是那个相对小的表，也就是“小表”。  

  例2：

  ```
  select t1.b,t2.* from  t1  straight_join t2 on (t1.b=t2.b) where t2.id<=100;
  select t1.b,t2.* from  t2  straight_join t1 on (t1.b=t2.b) where t2.id<=100;
  ```

  表t1 和 t2都是只有100行参加join。但是，这两条语句每次查询放入join_buffer中的数据是不一样的： 

  - 表t1只查字段b，因此如果把t1放到join_buffer中，则join_buffer中只需要放入b的值；
  - 表t2需要查所有的字段，因此如果把表t2放到join_buffer中的话，就需要放入三个字段id、a和b。

  所以应该选择表t1作为驱动表，只需要一列参与join的表t1”是那个相对小的表。 

  **在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与join的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。** 

######  Batched Key Acess(BKA) 

* Multi-Range Read优化 (MRR) 

  这个优化的主要目的是尽量**使用顺序读盘**。 

  **因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。** 

  *  MRR优化的执行流程：

    1. 根据索引a，定位到满足条件的记录，将id值放入read_rnd_buffer中;
    2. 将read_rnd_buffer中的id进行递增排序；
    3. 排序后的id数组，依次到主键id索引中查记录，并作为结果返回。

    read_rnd_buffer的大小是由read_rnd_buffer_size参数控制的。如果步骤1中，read_rnd_buffer放满了，就会先执行完步骤2和3，然后清空read_rnd_buffer。之后继续找索引a的下个记录，并继续循环。 

    ![img](https://static001.geekbang.org/resource/image/d5/c7/d502fbaea7cac6f815c626b078da86c7.jpg) 

    *  固定使用MRR 

       设置`set optimizer_switch="mrr_cost_based=off"` 

  explain结果中，可以看到**Extra字段多了Using MRR，表示的是用上了MRR优化**。 

  **MRR能够提升性能的核心**在于，这条查询语句在索引a上做的是一个**范围查询**（也就是说，这是一个多值查询），可以得到足够多的主键id。这样通过排序以后，再去主键索引查数据，才能体现出“顺序性”的优势。 

* Batched Key Acess(BKA) 

  MySQL在5.6版本后开始引入Batched Key Acess(BKA)算法； **这个BKA算法，其实就是对NLJ算法的优化。** 

  NLJ算法执行的逻辑是：从驱动表t1，一行行地取出a的值，再到被驱动表t2去做join。也就是说，对于表t2来说，每次都是匹配一个值。这时，MRR的优势就用不上了。 

  怎么才能一次性地多传些值给表t2呢？ 

  把表t1的数据取出来一部分，先放到一个临时内存join_buffer( join_buffer 在BNL算法里的作用，是暂存驱动表的数据。但是在NLJ算法里并没有用，刚好就可以复用join_buffer到BKA算法中。 ) 

  * BKA算法的流程

    ![img](https://static001.geekbang.org/resource/image/31/7e/31d85666542b9cb0b47a447a8593a47e.jpg) 

     如果join buffer放不下所有数据，就会把数据分成多段执行上图的流程。 

  *  BKA算法到底要怎么启用呢？ 

    ```
    set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';
    ```

     其中，前两个参数的作用是要启用MRR。这么做的原因是，**BKA算法的优化要依赖于MRR**。 

###### BNL算法的优化

BNL算法对系统的影响主要包括三个方面：

1. 可能会多次扫描被驱动表，占用磁盘IO资源；
2. 判断join条件需要执行M*N次对比（M、N分别是两张表的行数），如果是大表就会占用非常多的CPU资源；
3. 可能会导致Buffer Pool的热数据被淘汰，影响内存命中率。

执行语句之前，需要**通过理论分析和查看explain结果的方式，确认是否要使用BNL算法**。如果确认优化器会使用BNL算法，就需要做优化。**优化的常见做法是，给被驱动表的join字段加上索引，把BNL算法转成BKA算法。** 

*  不适合在被驱动表上建索引的情况

  比如低频的SQL语句，创建一个索引就很浪费了。 

  可以考虑使用临时表：

  1. 把表t2中满足条件的数据放在临时表tmp_t中；
  2. 为了让join使用BKA算法，给临时表tmp_t的字段b加上索引；
  3. 让表t1和tmp_t做join操作。

  ```
  create temporary table temp_t(id int primary key, a int, b int, index(b))engine=innodb;
  insert into temp_t select * from t2 where b>=1 and b<=2000;
  select * from t1 join temp_t on (t1.b=temp_t.b);
  ```

不论是在原表上加索引，还是用有索引的临时表，**思路都是让join语句能够用上被驱动表上的索引，来触发BKA算法**，提升查询性能。 

###### 扩展-hash join

如果BNL算法中join_buffer里面维护的不是一个无序数组，而是一个哈希表的话，那么就不是10亿次判断，而是100万次hash查找。 这也正是MySQL的优化器和执行器一直被诟病的一个原因：不支持哈希join。

 这个优化思路，我们可以自己实现在业务端。实现流程：

1. `select * from t1;`取得表t1的全部1000行数据，在业务端存入一个hash结构，比如C++里的set、PHP的dict这样的数据结构。
2. `select * from t2 where b>=1 and b<=2000;` 获取表t2中满足条件的2000行数据。
3. 把这2000行数据，一行一行地取到业务端，到hash结构的数据表中寻找匹配的数据。满足匹配的条件的这行数据，就作为结果集的一行。

###### 优化方法总结 

1. BKA优化是MySQL已经内置支持的，建议你默认使用；
2. BNL算法效率低，建议你都尽量转成BKA算法。优化的方向就是给被驱动表的关联字段加上索引；
3. 基于临时表的改进方案，对于能够提前过滤出小数据的join语句来说，效果还是很好的；
4. MySQL目前的版本还不支持hash join，但你可以配合应用端自己模拟出来，理论上效果要好于临时表的方案。

###### 好问题

*  如果用left join的话，左边的表一定是驱动表吗？ 
*  如果两个表的join包含多个条件的等值匹配，是都要写到on里面呢，还是只把一个条件写到on里面，其他条件写到where部分？ 

例： 

```
create table a(f1 int, f2 int, index(f1))engine=innodb;
create table b(f1 int, f2 int)engine=innodb;
insert into a values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6);
insert into b values(3,3),(4,4),(5,5),(6,6),(7,7),(8,8);

select * from a left join b on(a.f1=b.f1) and (a.f2=b.f2); /*Q1*/
select * from a left join b on(a.f1=b.f1) where (a.f2=b.f2);/*Q2*/
```

![img](https://static001.geekbang.org/resource/image/87/bd/871f890532349781fdc4a4287e9f91bd.png)

这两个left join语句的语义逻辑并不相同：

![img](https://static001.geekbang.org/resource/image/b7/17/b7f27917ceb0be90ef7b201f2794c817.png) 

- 驱动表是表a，被驱动表是表b；
- 由于表b的f1字段上没有索引，所以使用的是Block Nexted Loop Join（简称BNL） 算法。

 这条语句的执行流程：

1. 把表a的内容读入join_buffer 中。因为是select * ，所以字段f1和f2都被放入join_buffer了。
2. 顺序扫描表b，对于每一行数据，判断join条件（也就是a.f1=b.f1 and a.f2=b.f2)是否满足，满足条件的记录, 作为结果集的一行返回。如果语句中有where子句，需要先判断where部分满足条件后，再返回。
3. 表b扫描完成后，对于没有被匹配的表a的行（在这个例子中就是(1,1)、(2,2)这两行），把剩余字段补上NULL，再放入结果集中。

![img](https://static001.geekbang.org/resource/image/8f/d7/8fd4b4b179fb84caaecece84b6406ad7.jpg) 

 Q2的expain结果：

![img](https://static001.geekbang.org/resource/image/f5/9c/f5712c56dc84d331990409a5c313ea9c.png) 

这条语句是以表b为驱动表的。而如果一条join语句的Extra字段什么都没写的话，就表示使用的是Index Nested-Loop Join（简称NLJ）算法。 

语句Q2的执行流程是这样的：顺序扫描表b，每一行用b.f1到表a中去查，匹配到记录后判断a.f2=b.f2是否满足，满足条件的话就作为结果集的一部分返回。 

**为什么语句Q1和Q2这两个查询的执行流程会差距这么大呢？** 

在MySQL里，**NULL跟任何值执行等值判断和不等值判断的结果，都是NULL**。这里包括， select NULL = NULL 的结果，也是返回NULL。 

因此，语句Q2里面where a.f2=b.f2就表示，查询结果里面不会包含b.f2是NULL的行，这样这个left join的语义就是“找到这两个表里面，f1、f2对应相同的行。对于表a中存在，而表b中匹配不到的行，就放弃”。 

这条语句虽然用的是left join，但是语义跟join是一致的。 

因此，**优化器就把这条语句的left join改写成了join，然后因为表a的f1上有索引，就把表b作为驱动表，这样就可以用上NLJ 算法。** 

 show warnings查看结果：

![img](https://static001.geekbang.org/resource/image/d7/ab/d74878e7469edb8b713a18c6158530ab.png) 

所以即使我们在SQL语句中写成left join，执行过程还是有可能不是从左到右连接的。也就是说，**使用left join时，左边的表不一定是驱动表。** 

**如果需要left join的语义，就不能把被驱动表的字段放在where条件里面做等值判断或不等值判断，必须都写在on里面，而join语句将判断条件是否全部放在on部分就没有区别了 ** 

#### 用户临时表

######  临时表与内存表的区别

*  内存表

  指的是使用Memory引擎的表，**建表语法是create table … engine=memory**。这种表的**数据都保存在内存里，系统重启的时候会被清空**，但是表结构还在。 

*  临时表 

  可以使用各种引擎类型 。如果是使用InnoDB引擎或者MyISAM引擎的临时表，写数据的时候是写到磁盘上的。当然，临时表也可以使用Memory引擎。 

###### 临时表的特性

1.  建表语法是create temporary table …。 
2.  一个临时表只能被创建它的session访问，对其他线程不可见。 
3.  临时表可以与普通表同名。 
4.  session A内有同名的临时表和普通表的时候，show create语句，以及增删改查语句访问的是临时表。 
5.  show tables命令不显示临时表。 

由于临时表只能被创建它的session访问，所以在这个**session结束的时候，会自动删除临时表**。 

**临时表特别适合join优化这种场景 。为什么呢？  ** 

1. 不同session的临时表是可以重名的，如果有多个session同时执行join优化，**不需要担心表名重复导致建表失败的问题**。 
2. 不需要担心数据删除问题。如果使用普通表，在流程执行过程中客户端发生了异常断开，或者数据库发生异常重启，还需要专门来清理中间过程中生成的数据表。**而临时表由于会自动回收**，所以不需要这个额外的操作。 

###### 临时表的应用

由于不用担心线程之间的重名冲突，临时表经常会被**用在复杂查询的优化过程中**。

其中，分库分表系统的跨库查询就是一个典型的使用场景。 

一般分库分表的场景，就是要把一个逻辑上的大表分散到不同的数据库实例上。比如。将一个大表ht，按照字段f，拆分成1024个分表，然后分布到32个数据库实例上。 

![img](https://static001.geekbang.org/resource/image/dd/81/ddb9c43526dfd9b9a3e6f8c153478181.jpg) 

但是，如果这个表上还有另外一个索引k，查询语句：

```
select v from ht where k >= M order by t_modified desc limit 100;
```

由于查询条件里面没有用到分区字段f，只能到所有的分区中去查找满足条件的所有行，然后统一做order by 的操作；有两种比较常用的思路：

**第一种思路是，**在proxy层的进程代码中实现排序。这种方式的优势是处理速度快，拿到分库的数据以后，直接在内存中参与计算。  这个方案的缺点也比较明显：  

1. 需要的开发工作量比较大；如果涉及到复杂的操作，比如group by，甚至join这样的操作，对中间层的开发能力要求比较高；  
2.  对proxy端的压力比较大，尤其是很容易出现内存不够用和CPU瓶颈的问题。 

**另一种思路就是，**把各个分库拿到的数据，汇总到一个MySQL实例的一个表中，然后在这个汇总实例上做逻辑操作。 

执行流程可以类似这样： 

1. 在汇总库上创建一个临时表temp_ht，表里包含三个字段v、k、t_modified；

2. 在各个分库上执行

   ```
   select v,k,t_modified from ht_x where k >= M order by t_modified desc limit 100;
   ```

3. 把分库执行的结果插入到temp_ht表中；

4. 执行

   ```
   select v from temp_ht order by t_modified desc limit 100; 
   ```

    得到结果。 

![img](https://static001.geekbang.org/resource/image/f5/0d/f5ebe0f5af37deeb4d0b63d6fb11fc0d.jpg) 

**在实践中，我们往往会发现每个分库的计算量都不饱和，所以会直接把临时表temp_ht放到32个分库中的某一个上。** 

###### 为什么临时表可以重名？

```
create temporary table temp_t(id int primary key)engine=innodb;
```

执行这个语句的时候，MySQL要给这个InnoDB表创建一个frm文件保存表结构定义，还要有地方保存表数据。 

**这个frm文件放在临时文件目录下，文件名的后缀是.frm，前缀是“#sql{进程id}_{线程id}_序列号”**。可以使用select @@tmpdir命令，来显示实例的临时文件目录。 

![img](https://static001.geekbang.org/resource/image/22/1b/22078eab5c7688c9fbfd6185555bd91b.png) 

MySQL维护数据表，除了物理上要有文件外，**内存里面也有一套机制区别不同的表，每个表都对应一个table_def_key。** 

- 一个普通表的table_def_key的值是由“库名+表名”得到的，所以如果你要在同一个库下创建两个同名的普通表，创建第二个表的过程中就会发现table_def_key已经存在了。
- 而对于临时表，table_def_key在“库名+表名”基础上，又加入了“server_id+thread_id”。

session A和sessionB创建的两个临时表t1，**它们的table_def_key不同，磁盘文件名也不同，因此可以并存**。 

在实现上，每个线程都维护了自己的临时表链表。这样每次session内操作表的时候，先遍历链表，检查是否有这个名字的临时表，如果有就优先操作临时表，如果没有再操作普通表；在session结束的时候，对链表里的每个临时表，执行 “DROP TEMPORARY TABLE +表名”操作。 

###### 临时表和主备复制

```
create table t_normal(id int primary key, c int)engine=innodb;/*Q1*/
create temporary table temp_t like t_normal;/*Q2*/
insert into temp_t values(1,1);/*Q3*/
insert into t_normal select * from temp_t;/*Q4*/
```

如果关于临时表的操作都不记录，那么在备库就只有create table t_normal表和insert into t_normal select * from temp_t这两个语句的binlog日志，备库在执行到insert into t_normal的时候，就会报错“表temp_t不存在”。 

**如果当前的binlog_format=row，那么跟临时表有关的语句，就不会记录到binlog里。也就是说，只在binlog_format=statment/mixed 的时候，binlog中才会记录临时表的操作。** 

这种临时表，是用户自己创建的 ，也可以称为**用户临时表**。与它相对应的，就是内部临时表 

#### 内部临时表

什么情况下会使用内部临时表？

* union
* group by

###### union 执行流程

* union

   语义是，取这两个子查询结果的并集，重复的行只保留一行。 

例： ![img](https://static001.geekbang.org/resource/image/40/4e/402cbdef84eef8f1b42201c6ec4bad4e.png) 

 explain结果Extra字段Using temporary，表示使用了临时表    

 执行流程：

1.  创建一个内存临时表，这个临时表只有一个整型字段f，并且f是主键字段。 
2.  执行第一个子查询，得到1000这个值，并存入临时表中。 
3.  执行第二个子查询： 
   - 拿到第一行id=1000，试图插入临时表中。但由于1000这个值已经存在于临时表了，违反了唯一性约束，所以插入失败，然后继续执行；
   - 取到第二行id=999，插入临时表成功。
4.  从临时表中按行取出数据，返回结果，并删除临时表，结果中包含两行数据分别是1000和999。 

![img](https://static001.geekbang.org/resource/image/5d/0e/5d038c1366d375cc997005a5d65c600e.jpg) 

这里的**内存临时表起到了暂存数据的作用**，而且还用上了临时表主键id的唯一性约束，实现了union的语义。 

如果把上面这个语句中的union**改成union all的话，就没有了“去重”的语义**。这样执行的时候，就依次执行子查询，得到的结果**直接作为结果集的一部分，发给客户端。因此也就不需要临时表了**。 

![img](https://static001.geekbang.org/resource/image/c1/6d/c1e90d1d7417b484d566b95720fe3f6d.png) 

Extra字段显示的是Using index，表示只使用了覆盖索引，没有用临时表了。 

###### group by 执行流程

例： select id%10 as m, count(*) as c from t1 group by m; 

![img](https://static001.geekbang.org/resource/image/3d/98/3d1cb94589b6b3c4bb57b0bdfa385d98.png) 

Extra字段里面， 可以看到三个信息： 

1. Using index，表示这个语句使用了覆盖索引，选择了索引a，不需要回表；
2. Using temporary，表示使用了临时表；
3. Using filesort，表示需要排序。

执行流程：

1. 创建内存临时表，表里有两个字段m和c，主键是m；
2. 扫描表t1的索引a，依次取出叶子节点上的id值，计算id%10的结果，记为x；
   - 如果临时表中没有主键为x的行，就插入一个记录(x,1);
   - 如果表中有主键为x的行，就将x这一行的c值加1；
3. 遍历完成后，再根据字段m做排序，得到结果集返回给客户端。

![img](https://static001.geekbang.org/resource/image/03/54/0399382169faf50fc1b354099af71954.jpg) 

 如果需求并不需要对结果进行排序，那可以在SQL语句末尾增加order by null：

```
select id%10 as m, count(*) as c from t1 group by m order by null;
```

**这样就跳过了最后排序的阶段，直接从临时表中取数据返回。** 

**内存临时表的大小是有限制的，参数tmp_table_size就是控制这个内存大小的，默认是16M。**  如果内存临时表大小到达了上限，这时候就会**把内存临时表转成磁盘临时表。**  

###### group by 优化方法 --索引

执行group by语句为什么需要临时表？ 

group by的语义逻辑，是统计不同的值出现的个数。但是，由于每一行的id%100的**结果是无序的，所以我们就需要有一个临时表，来记录并统计结果**。 

![img](https://static001.geekbang.org/resource/image/5c/19/5c4a581c324c1f6702f9a2c70acddd19.jpg) 

 如果可以确保输入的数据是有序的，那么计算group by的时候，就只需要从左到右，顺序扫描，依次累加：

- 当碰到第一个1的时候，已经知道累积了X个0，结果集里的第一行就是(0,X);
- 当碰到第一个2的时候，已经知道累积了Y个1，结果集里的第二行就是(1,Y);

按照这个逻辑执行的话，扫描到整个输入的数据结束，就可以拿到group by的结果，不需要临时表，也不需要再额外排序。 

*  generated column机制 

  MySQL 5.7版本支持了generated column机制，用来实现列数据的关联更新。你可以创建一个列z，然后在z列上创建一个索引 

  ```
  alter table t1 add column z int generated always as(id % 100), add index(z);
  ```

  这样，索引z上的数据就是类似图10这样有序的了。上面的group by语句就可以改成： 

  ```
  select z, count(*) as c from t1 group by z;
  ```

  从Extra字段可以看到，这个语句的执行**不再需要临时表，也不需要排序了**。 

###### group by优化方法 --直接排序

如果碰上不适合创建索引的场景，还是要老老实实做排序的；这时候的group by要怎么优化呢？ 

MySQL有没有让我们直接走磁盘临时表的方法呢？ 

在group by语句中**加入SQL_BIG_RESULT**这个提示（hint），就可以告诉优化器：这个语句涉及的数据量很大，请直接用磁盘临时表。 

MySQL的优化器一看，磁盘临时表是B+树存储，存储效率不如数组来得高。所以，既然你告诉我数据量很大，那从磁盘空间考虑，还是直接用数组来存吧。 

```
select SQL_BIG_RESULT id%100 as m, count(*) as c from t1 group by m;
```

执行流程：

1.  初始化sort_buffer，确定放入一个整型字段，记为m； 
2.  扫描表t1的索引a，依次取出里面的id值, 将 id%100的值存入sort_buffer中； 
3.  扫描完成后，对sort_buffer的字段m做排序 
4.  排序完成后，就得到了一个有序数组。 

 根据有序数组，得到数组里面的不同值，以及每个值的出现次数。 

![img](https://static001.geekbang.org/resource/image/82/6a/8269dc6206a7ef20cb515c23df0b846a.jpg) 

![img](https://static001.geekbang.org/resource/image/83/ec/83b6cd6b3e37dfbf9699cf0ccc0f1bec.png) 

从Extra字段可以看到，**这个语句的执行没有再使用临时表，而是直接用了排序算法。** 

* group by小结
  *  如果对group by语句的结果没有排序要求，要在语句后面加 order by null； 
  *  尽量让group by过程用上表的索引，确认方法是explain结果里没有Using temporary 和 Using filesort； 
  *  如果group by需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大tmp_table_size参数，来避免用到磁盘临时表； 
  *  如果数据量实在太大，使用SQL_BIG_RESULT这个提示，来告诉优化器直接使用排序算法得到group by的结果。 

###### distinct 和 group by的性能

例：

```
select a from t group by a order by null;
select distinct a from t;
```

**group by语句按照字段a做分组，相同的a的值只返回一行。而这就是distinct的语义**，所以不需要执行聚合函数时，distinct 和group by这两条语句的语义和执行流程是相同的，**因此执行性能也相同**。 

######  MySQL什么时候会使用内部临时表？ 

1.  如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果； 
2.  join_buffer是无序数组，sort_buffer是有序数组，临时表是二维表结构； 
3.  如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。  比如例子中，**union需要用到唯一索引约束， group by还需要用到另外一个字段来存累积计数**。 

####  收缩表空间

* innodb_file_per_table

  表数据既可以存在共享表空间里，也可以是单独的文件。  由参数innodb_file_per_table控制的

  1.  设置为OFF表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起； 

  2.  设置为ON表示的是，每个InnoDB表数据存储在一个以 .ibd为后缀的文件中。 

      从MySQL 5.6.6版本开始，它的默认值就是ON了。 **建议都将这个值设置为ON** 

      在你不需要这个表的时候，通过drop table命令 ，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。  

*  表中的数据被删除了，但是表空间却没有被回收？

  **delete命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的**。也就是说，通过delete命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。 

  **不止是删除数据会造成空洞，插入数据也会。** 如果数据是随机插入的，就可能造成索引的数据页分裂，进而造成空洞； 更新索引上的值，可以理解为删除一个旧的值，再插入一个新值 ，因此这也是会造成空洞的。 

  也就是说，**经过大量增删改的表，都是可能是存在空洞的**。  而**重建表，就可以达到收缩表空间**的目的。 

* 重建表

  可以使用alter table A engine=InnoDB命令来重建表。 

   **MySQL 5.5及之前的版本，这个命令是会阻塞DML的** 

   在**MySQL 5.6版本开始引入的Online DDL，**  重建表的过程中 允许对表做增删改操作 

*  重建表的流程： 

  1. 建立一个临时文件，扫描表A主键的所有数据页；
  2. 用数据页中表A的记录生成B+树，存储到临时文件中；
  3. 生成临时文件的过程中，将所有对A的操作记录在一个日志文件（row log）中，对应的是图中state2的状态；
  4. 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表A相同的数据文件，对应的就是图中state3的状态；
  5. 用临时文件替换表A的数据文件。

   ![img](https://static001.geekbang.org/resource/image/2d/f0/2d1cfbbeb013b851a56390d38b5321f0.png) 

  这些重建方法**都会扫描原表数据和构建临时文件**。**对于很大的表来说，这个操作是很消耗IO和CPU资源**的。因此，如果是线上服务，你要很小心地控制操作时间。如果想要比较安全的操作的话，推荐使用GitHub开源的gh-ost来做。 

* Online 和 inplace

  在MySQL 5.5版本之前， 我们把表A中的数据导出来的存放位置叫作tmp_table。这是一个临时表，是在server层创建的。 

  MySQL 5.6版本开始引入的Online DDL，根据表A重建出来的数据是放在“tmp_file”里的，这个临时文件是InnoDB在内部创建出来的。整个DDL过程都在InnoDB内部完成。**对于server层来说，没有把数据挪动到临时表，是一个“原地”操作，这就是“inplace”名称的来源。** 

   alter table t engine=InnoDB，其实隐含的意思是： 

  ```
  alter table t engine=innodb,ALGORITHM=inplace;
  ```

   跟inplace对应的就是拷贝表的方式了，用法是： 

  ```
  alter table t engine=innodb,ALGORITHM=copy;
  ```

   当你使用ALGORITHM=copy的时候，表示的是强制拷贝表，对应的流程就是MySQL 5.5版本之前

  1.   DDL过程如果是Online的，就一定是inplace的； 
  2.  反过来未必，也就是说inplace的DDL，有可能不是Online的。 如添加全文索引（FULLTEXT index）和空间索引(SPATIAL index)就属于这种情况。 

* 如果你有一个1TB的表，现在磁盘间是1.2TB，能不能做一个inplace的DDL呢？ 

   答案是不能。因为，tmp_file也是要占用临时空间的。 

####  临时性提升性能方案

**这些临时方案都是有损的**

###### 短连接风暴

**连接异常断开是常有的事，代码里一定要有正确地重连并重试的机制**。 

正常的短连接模式就是连接到数据库后，执行很少的SQL语句就断开，下次需要的时候再重连。如果使用的是短连接，在业务高峰期的时候，就可能出现连接数突然暴涨的情况。 

 MySQL建立连接的过程，成本是很高的。除了正常的网络连接三次握手外，还需要做登录权限判断和获得这个连接的数据读写权限。 

 **短连接模型存在一个风险，就是一旦数据库处理得慢一些，连接数就会暴涨**。 

 **max_connections**参数，用来控制一个MySQL实例同时存在的连接数的上限，超过这个值，系统就会拒绝接下来的连接请求，并报错提示“**Too many connections**” 

在机器负载比较高的时候，处理现有请求的时间变长，每个连接保持的时间也更长。这时，再有新建连接的话，就可能会超过max_connections的限制。 

调高max_connections的值是有风险的， 如果把它改得太大，让更多的连接都可以进来，那么系统的负载可能会进一步加大，大量的资源耗费在权限验证等逻辑上，结果可能是适得其反，已经连接的线程拿不到CPU资源去执行业务的SQL请求 

解决方法：

1.  **先处理掉那些占着连接但是不工作的线程**

   对于那些不需要保持的连接，我们可以通过**kill connection**主动踢掉。这个行为跟事先设置wait_timeout的效果是一样的( wait_timeout参数表示的是,一个线程空闲wait_timeout这么多秒之后，就会被MySQL直接断开连接 )

   在show processlist的结果里，踢掉显示为sleep的线程 

   如果是连接数过多，你**可以优先断开事务外空闲太久的连接**；如果这样还不够，再考虑断开事务内空闲太久的连接。 

   从服务端断开连接使用的是kill connection + id的命令，一个客户端处于sleep状态时，它的连接被服务端主动断开后，这个客户端并不会马上知道。直到客户端在发起下一个请求的时候，才会收到这样的报错“ERROR 2013 (HY000): Lost connection to MySQL server during query”。 

   从数据库端主动断开连接可能是有损的，尤其是**有的应用端收到这个错误后，不重新连接，而是直接用这个已经不能用的句柄重试查询**。**这会导致从应用端看上去，“MySQL一直没恢复”**。 

2.  **减少连接过程的消耗** 

   * 让数据库跳过权限验证阶段

     跳过权限验证的方法是：重启数据库，并使用**–skip-grant-tables**参数启动。这样，整个MySQL会跳过所有的权限验证阶段，包括连接过程和语句执行过程在内。 

     这种方法，风险极高，**尤其库外网可访问的话，就更不能这么做了**。 

     在MySQL 8.0版本里，如果你启用–skip-grant-tables参数，MySQL会默认把 **--skip-networking**参数打开，**表示这时候数据库只能被本地的客户端连接**。可见，MySQL官方对skip-grant-tables这个参数的安全问题也很重视。 

###### 慢查询性能问题

*  **索引没有设计好** 

  这种场景一般就是**通过紧急创建索引来解决**。MySQL 5.6版本以后，创建索引都支持Online DDL了，对于那种高峰期数据库已经被这个语句打挂了的情况，**最高效的做法就是直接执行alter table 语句**。 

   比较理想的是能够在备库先执行。假设现在的服务是一主一备 ，这个方案的大致流程是这样的： 

  1.  在备库B上执行 set sql_log_bin=off，也就是不写binlog，然后执行alter table 语句加上索引；
  2.  执行主备切换； 
  3.  这时候主库是B，备库是A。在A上执行 set sql_log_bin=off，然后执行alter table 语句加上索引。

  应该考虑类似gh-ost这样的方案，更加稳妥。但是**在需要紧急处理时，上面这个方案的效率是最高的**。

* **语句没写好** 

  **可以通过改写SQL语句来处理**。MySQL 5.7提供了query_rewrite功能，可以把输入的一种语句改写成另外一种模式。 

  例： 比如，语句被错误地写成了 select * from t where id + 1 = 10000，可以通过下面的方式，增加一个语句改写规则：

  ```
  mysql> insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values ("select * from t where id + 1 = ?", "select * from t where id = ? - 1", "db1");
  call query_rewrite.flush_rewrite_rules();
  ```

  通过下面方法确认改写规则是否生效 ：

  ![img](https://static001.geekbang.org/resource/image/47/8a/47a1002cbc4c05c74841591d20f7388a.png) 

*  **MySQL选错了索引** 

   **应急方案就是给这个语句加上force index** 

   同样地，使用查询重写功能，给原来的语句加上force index，也可以解决这个问题。 

 **索引没设计好和语句没写好这两种情况，恰恰是完全可以避免的**：

1. 上线前，在测试环境，把慢查询日志（slow log）打开，并且把long_query_time设置成0，确保每个语句都会被记录入慢查询日志；
2. 在测试表里插入模拟线上的数据，做一遍回归测试；
3. 观察慢查询日志里每类语句的输出，特别留意Rows_examined字段是否与预期一致。

如果新增的SQL语句不多，手动跑一下就可以。而如果是新项目的话，或者是修改了原有项目的 表结构设计，全量回归测试都是必要的。  这时候，你需要工具帮你检查所有的SQL语句的返回结果。比如pt-query-digest 

###### QPS（每秒查询数）突增问题

####  提升性能方法

###### binlog的写入机制

 事务执行过程中，先把日志写到binlog cache，事务提交的时候，再把binlog cache写到binlog文件中。 

* binlog cache

   一个事务的binlog是不能被拆开的，因此不论这个事务多大，也要确保一次性写入；所以系统给**binlog cache**分配了一片内存，**每个线程一个**，参数 binlog_cache_size用于控制单个线程内binlog cache所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。 

  事务提交的时候，执行器把binlog cache里的完整事务写入到binlog中，并清空binlog cache。 

![img](https://static001.geekbang.org/resource/image/9e/3e/9ed86644d5f39efb0efec595abb92e3e.png) 

 **每个线程有自己binlog cache，但是共用同一份binlog文件。** 

*  write，指的就是指把日志写入到文件系统的page cache，并没有把数据持久化到磁盘，所以速度比较快。 
*  fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为fsync才占磁盘的IOPS。 

*  sync_binlog 

   write 和fsync的时机，是由参数sync_binlog控制的： 

  1.  sync_binlog=0的时候，表示每次提交事务都只write，不fsync； 
  2.  sync_binlog=1的时候，表示每次提交事务都会执行fsync； 
  3.  sync_binlog=N(N>1)的时候，表示每次提交事务都write，但累积N个事务后才fsync。 

  因此，在**出现IO瓶颈的场景里，将sync_binlog设置成一个比较大的值，可以提升性能**。 考虑到丢失日志量的可控性， 一般不建议将这个参数设成0，比较常见的是**将其设置为100~1000中的某个数值**。 

  但是，将sync_binlog设置为N，对应的风险是：如果主机发生异常重启，会丢失最近N个事务的binlog日志。 

###### redo log的写入机制

事务在执行过程中，生成的redo log是要先写到redo log buffer的。 

redo log buffer里面的内容，**是不是每次生成后都要直接持久化到磁盘呢**？  

答案是，不需要。  如果事务执行期间MySQL发生异常重启，那这部分日志就丢了。由于事务并没有提交，所以这时日志丢了也不会有损失。 

事务还没提交的时候，redo log buffer中的部分日志有没有可能被持久化到磁盘呢？ 

答案是，确实会有。 

* redo log 的三种状态：

  1.  存在redo log buffer中，物理上是在MySQL进程内存中 
  2.  写到磁盘(write)，但是没有持久化（fsync)，物理上是在文件系统的page cache里面 
  3.  持久化到磁盘，对应的是hard disk 

  ![img](https://static001.geekbang.org/resource/image/9d/d4/9d057f61d3962407f413deebc80526d4.png) 

 日志写到redo log buffer是很快的，wirte到page cache也差不多，但是持久化到磁盘的速度就慢多了。 

*  innodb_flush_log_at_trx_commit 

   为了控制redo log的写入策略，InnoDB提供了innodb_flush_log_at_trx_commit参数，它有三种可能取值： 

  1.  设置为0的时候，表示每次事务提交时都只是把redo log留在redo log buffer中; 
  2.  设置为1的时候，表示每次事务提交时都将redo log直接持久化到磁盘； 
  3.  设置为2的时候，表示每次事务提交时都只是把redo log写到page cache。 

InnoDB有一个后台线程，每隔1秒，就会把redo log buffer中的日志，调用write写到文件系统的page cache，然后调用fsync持久化到磁盘。 

 **一个没有提交的事务的redo log，也是可能已经持久化到磁盘的。** 

 **除了后台线程每秒一次的轮询操作外**，还有两种场景会让一个没有提交的事务的redo log写入到磁盘中。 

1.  **redo log buffer占用的空间即将达到 innodb_log_buffer_size一半的时候，后台线程会主动写盘。** 
2.  **并行的事务提交的时候，顺带将这个事务的redo log buffer持久化到磁盘。** 

如果把innodb_flush_log_at_trx_commit设置成1，那么**redo log在prepare阶段就要持久化一次**，因为有一个崩溃恢复逻辑是要依赖于prepare 的redo log，再加上binlog来恢复的。 

*  MySQL的“双1”配置 

  指的就是sync_binlog和innodb_flush_log_at_trx_commit都设置成 1。也就是说，**一个事务完整提交前，需要等待两次刷盘，一次是redo log（prepare 阶段），一次是binlog**。 

###### 组提交 

*  LSN 

  日志逻辑序列号（log sequence number，LSN）是单调递增的，用来对应redo log的一个个写入点。  每次写入长度为length的redo log， LSN的值就会加上length。 

 一次组提交里面，组员越多，节约磁盘IOPS的效果越好。但如果只有单线程压测，那就只能老老实实地一个事务对应一次持久化操作了。 

 在并发更新场景下，第一个事务写完redo log buffer以后，接下来这个fsync越晚调用，组员可能越多，节约IOPS的效果就越好。 

*  binlog_group_commit_sync_delay 

   binlog_group_commit_sync_delay参数，表示延迟多少微秒后才调用fsync; 

*  binlog_group_commit_sync_no_delay_count 

   binlog_group_commit_sync_no_delay_count参数，表示累积多少次以后才调用fsync。 

 **这两个条件是或的关系，也就是说只要有一个满足条件就会调用fsync。** 

 所以，当binlog_group_commit_sync_delay设置为0的时候，binlog_group_commit_sync_no_delay_count也无效了。 

*  WAL机制主要得益于两个方面： 
  1.  redo log 和 binlog都是顺序写，磁盘的顺序写比随机写速度要快；
  2.  组提交机制，可以大幅度降低磁盘的IOPS消耗。  

###### 提升性能的三种方法

**瓶颈在IO上，可以通过哪些方法来提升性能呢？** 

1. 设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count参数，减少binlog的写盘次数。

   这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。 

2.  将sync_binlog 设置为大于1的值（比较常见是100~1000） 

    这样做的风险是，主机掉电时会丢binlog日志。 

3.  将innodb_flush_log_at_trx_commit设置为2。 

    这样做的风险是，主机掉电的时候会丢数据。 

 不建议把innodb_flush_log_at_trx_commit 设置成0，redo log写到文件系统的page cache的速度也是很快的，所以将这个参数设置成2跟设置成0其实性能差不多，但这样做MySQL异常重启时就不会丢数据了，相比之下风险会更小。 

#### 分区表

###### 分区表是什么？

例： 

```
PARTITION BY RANGE (YEAR(ftime))
(PARTITION p_2017 VALUES LESS THAN (2017) ENGINE = InnoDB,
 PARTITION p_2018 VALUES LESS THAN (2018) ENGINE = InnoDB,
 PARTITION p_2019 VALUES LESS THAN (2019) ENGINE = InnoDB,
PARTITION p_others VALUES LESS THAN MAXVALUE ENGINE = InnoDB);
```

![img](https://static001.geekbang.org/resource/image/06/f5/06f041129783533de9c75580f9decdf5.png) 

 这个表包含了一个.frm文件和4个.ibd文件，每个分区对应一个.ibd文件。 

 也就是说： 

- **对于引擎层来说，这是4个表；**
- **对于Server层来说，这是1个表。**

######  分区表的引擎层行为 

 insert into t values('2017-4-1',1),('2018-4-1',1); 

![img](https://static001.geekbang.org/resource/image/d2/c7/d28d6ab873bd8337d88812d45b9266c7.png) 

如果是普通表，加锁范围如下：

![img](https://static001.geekbang.org/resource/image/27/d2/273c9ca869f5b52621641d73eb6f72d2.jpg) 

如果是分区表，加锁范围如下：

![img](https://static001.geekbang.org/resource/image/92/5c/92f63aba0b24adefac7316c75463b95c.jpg) 

 session A的select语句其实只操作了分区p_2018，因此加锁范围就是图4中深绿色的部分。 

 所以，session B要写入一行ftime是2018-2-1的时候是可以成功的，而要写入2017-12-1这个记录，就要等session A的间隙锁。 

* 手动分表和分区表有什么区别？

   其实这两个方案的区别，主要是在server层上。从server层看，  **分区表一个被广为诟病的问题：打开表的行为。** 

###### 分区策略

* **通用分区策略** 

   MyISAM分区表使用的是**通用分区策略**，**每次访问分区都由server层控制**；

  open_files_limit参数使用的是默认值1024，那么就会在访问这个表的时候，由于需要打开所有的文件，导致打开表文件的个数超过了上限而报错。 

  ![img](https://static001.geekbang.org/resource/image/ab/e7/abfa0054ec43d97fb18ba3c1c8829ae7.png)  

*  **本地分区策略** 

  从MySQL 5.7.9开始，InnoDB引擎引入了**本地分区策略**， 这个策略是**在InnoDB内部自己管理打开分区的行为**。  **不会像通用分区策略那样报错，因为如果打开文件数过多，就会淘汰之前打开的文件句柄（暂时关掉）**。 

  从MySQL 8.0版本开始，就不允许创建MyISAM分区表了，只允许创建已经实现了本地分区策略的引擎。 

###### 分区表的server层行为

例： ![img](https://static001.geekbang.org/resource/image/0e/81/0eca5a3190161e59ea58493915bd5e81.png) 

虽然session B只需要操作p_2107这个分区，但是由于session A持有整个表t的MDL锁，就导致了session B的alter语句被堵住。  如果使用的是普通分表，那么当在truncate一个分表的时候，肯定不会跟另外一个分表上的查询语句，出现MDL锁冲突。 

小结：

1. MySQL在第一次打开分区表的时候，需要访问所有的分区；
2. 在server层，认为这是同一张表，因此所有分区共用同一个MDL锁；
3. 在引擎层，认为这是不同的表，会根据分区表规则，只访问必要的分区。

###### 分区表的应用场景

相对于用户分表来说，使用分区表的业务代码更简洁。还有，分区表可以很方便的清理历史数据。 

如果一项业务跑的时间足够长，往往就会有根据时间删除历史数据的需求。这时候，按照时间分区的分区表，就可以直接通过alter table t drop partition …这个语法删掉分区，从而删掉过期的历史数据。  与使用delete语句删除数据相比，优势是速度快、对系统影响小。 

###### 总结

例子中是范围分区（range），MySQL还支持hash分区、list分区等分区方法。  

分区表跟用户分表比起来，有两个绕不开的问题：**一个是第一次访问的时候需要访问所有分区，另一个是共用MDL锁**。 因此，**如果要使用分区表，就不要创建太多的分区。** 

有两个问题需要注意： 

1. **分区并不是越细越好**。实际上，单表或者单分区的数据一千万行，只要没有特别大的索引，对于现在的硬件能力来说都已经是小表了。 
2. **分区也不要提前预留太多，在使用之前预先创建即可**。比如，如果是按月分区，每年年底时再把下一年度的12个新分区创建上即可。对于没有数据的历史分区，要及时的drop掉。 

#### 如何判断数据库是否出问题了

* select 1判断

  同时在执行的语句超过了设置的innodb_thread_concurrency的值，这时候系统其实已经不行了，但是通过select 1来检测系统，会认为系统还是正常的。 

* 查表判断

  一般的做法是，在系统库（mysql库）里创建一个表，比如命名为health_check，里面只放一行数据，然后定期执行： 

  ```
  select * from mysql.health_check; 
  ```

  使用这个方法，可以检测出由于并发线程过多导致的数据库不可用的情况。  空间满了以后，这种方法又会变得不好使。  更新事务要写binlog，而**一旦binlog所在磁盘的空间占用率达到100%，那么所有的更新语句和事务提交的commit语句就都会被堵住。但是，系统这时候还是可以正常读数据的。** 

* 更新判断

   常见做法是放一个timestamp字段，用来表示最后一次执行检测的时间：

  ```
  update mysql.health_check set t_modified=now();
  ```

  * 主备之间的更新冲突

    为了让主备之间的更新不产生冲突，我们可以在mysql.health_check表上存入多行数据，并用A、B的server_id做主键。 

    ```
    mysql> CREATE TABLE `health_check` (
      `id` int(11) NOT NULL,
      `t_modified` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,
      PRIMARY KEY (`id`)
    ) ENGINE=InnoDB;
    
    /* 检测命令 */
    insert into mysql.health_check(id, t_modified) values (@@server_id, now()) on duplicate key update t_modified=now();
    ```

  * **判定慢** 

    设想一个日志盘的IO利用率已经是100%的场景。这时候，整个系统响应非常慢，  而检测使用的**update命令，需要的资源很少**，所以可能在拿到IO资源的时候就可以提交成功，并且在超时时间N秒未到达之前就返回给了检测系统。 

* 内部统计

  MySQL 5.6版本以后提供的performance_schema库，就在file_summary_by_event_name表里统计了每次IO请求的时间。 

  *  打开redo log的时间监控 

    ```
    update setup_instruments set ENABLED='YES', Timed='YES' where name like '%wait/io/file/innodb/innodb_log_file%';
    ```

  *  怎么把这个信息用在实例状态诊断上呢？ 

    可以通过MAX_TIMER的值来判断数据库是否出问题了。比如可以设定阈值，单次IO请求时间超过200毫秒属于异常，然后使用类似下面这条语句作为检测逻辑：

    ```
    mysql> select event_name,MAX_TIMER_WAIT  FROM performance_schema.file_summary_by_event_name where event_name in ('wait/io/file/innodb/innodb_log_file','wait/io/file/sql/binlog') and MAX_TIMER_WAIT>200*1000000000;
    ```

    处理完成后， 把之前的统计信息清空。 

 **优先考虑update系统表，然后再配合增加检测performance_schema的信息的方案** 

